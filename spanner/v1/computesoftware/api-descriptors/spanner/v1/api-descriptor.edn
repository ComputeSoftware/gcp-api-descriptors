#:compute.gcp.descriptor{:name "spanner", :title "Cloud Spanner API", :api-version "v1", :revision "20200409", :endpoint #:compute.gcp.descriptor{:url "https://spanner.googleapis.com/", :batch-path "batch", :service-path ""}, :parameters {"callback" {"location" "query", "description" "JSONP", "type" "string"}, "uploadType" {"description" "Legacy upload protocol for media (e.g. \"media\", \"multipart\").", "type" "string", "location" "query"}, "key" {"description" "API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.", "type" "string", "location" "query"}, "access_token" {"description" "OAuth access token.", "type" "string", "location" "query"}, "oauth_token" {"location" "query", "description" "OAuth 2.0 token for the current user.", "type" "string"}, "prettyPrint" {"description" "Returns response with indentations and line breaks.", "type" "boolean", "default" "true", "location" "query"}, "alt" {"location" "query", "description" "Data format for response.", "default" "json", "enum" ["json" "media" "proto"], "type" "string", "enumDescriptions" ["Responses with Content-Type of application/json" "Media download with context-dependent Content-Type" "Responses with Content-Type of application/x-protobuf"]}, "$.xgafv" {"description" "V1 error format.", "type" "string", "enumDescriptions" ["v1 error format" "v2 error format"], "location" "query", "enum" ["1" "2"]}, "fields" {"location" "query", "description" "Selector specifying which fields to include in a partial response.", "type" "string"}, "upload_protocol" {"description" "Upload protocol for media (e.g. \"raw\", \"multipart\").", "type" "string", "location" "query"}, "quotaUser" {"description" "Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.", "type" "string", "location" "query"}}, :op->info {}, :schemas {"QueryPlan" {"description" "Contains an ordered list of nodes appearing in the query plan.", "type" "object", "properties" {"planNodes" {"type" "array", "items" {"$ref" "PlanNode"}, "description" "The nodes in the query plan. Plan nodes are returned in pre-order starting\nwith the plan root. Each PlanNode's `id` corresponds to its index in\n`plan_nodes`."}}, "id" "QueryPlan"}, "ListBackupOperationsResponse" {"properties" {"operations" {"description" "The list of matching backup long-running\noperations. Each operation's name will be\nprefixed by the backup's name and the operation's\nmetadata will be of type\nCreateBackupMetadata. Operations returned include those that are\npending or have completed/failed/canceled within the last 7 days.\nOperations returned are ordered by\n`operation.metadata.value.progress.start_time` in descending order starting\nfrom the most recently started operation.", "type" "array", "items" {"$ref" "Operation"}}, "nextPageToken" {"type" "string", "description" "`next_page_token` can be sent in a subsequent\nListBackupOperations\ncall to fetch more of the matching metadata."}}, "id" "ListBackupOperationsResponse", "description" "The response for\nListBackupOperations.", "type" "object"}, "TestIamPermissionsRequest" {"id" "TestIamPermissionsRequest", "description" "Request message for `TestIamPermissions` method.", "type" "object", "properties" {"permissions" {"description" "REQUIRED: The set of permissions to check for 'resource'.\nPermissions with wildcards (such as '*', 'spanner.*', 'spanner.instances.*') are not allowed.", "type" "array", "items" {"type" "string"}}}}, "Empty" {"type" "object", "properties" {}, "id" "Empty", "description" "A generic empty message that you can re-use to avoid defining duplicated\nempty messages in your APIs. A typical example is to use it as the request\nor the response type of an API method. For instance:\n\n    service Foo {\n      rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty);\n    }\n\nThe JSON representation for `Empty` is empty JSON object `{}`."}, "Expr" {"type" "object", "properties" {"title" {"description" "Optional. Title for the expression, i.e. a short string describing\nits purpose. This can be used e.g. in UIs which allow to enter the\nexpression.", "type" "string"}, "location" {"description" "Optional. String indicating the location of the expression for error\nreporting, e.g. a file name and a position in the file.", "type" "string"}, "description" {"description" "Optional. Description of the expression. This is a longer text which\ndescribes the expression, e.g. when hovered over it in a UI.", "type" "string"}, "expression" {"description" "Textual representation of an expression in Common Expression Language\nsyntax.", "type" "string"}}, "id" "Expr", "description" "Represents a textual expression in the Common Expression Language (CEL)\nsyntax. CEL is a C-like expression language. The syntax and semantics of CEL\nare documented at https://github.com/google/cel-spec.\n\nExample (Comparison):\n\n    title: \"Summary size limit\"\n    description: \"Determines if a summary is less than 100 chars\"\n    expression: \"document.summary.size() < 100\"\n\nExample (Equality):\n\n    title: \"Requestor is owner\"\n    description: \"Determines if requestor is the document owner\"\n    expression: \"document.owner == request.auth.claims.email\"\n\nExample (Logic):\n\n    title: \"Public documents\"\n    description: \"Determine whether the document should be publicly visible\"\n    expression: \"document.type != 'private' && document.type != 'internal'\"\n\nExample (Data Manipulation):\n\n    title: \"Notification string\"\n    description: \"Create a notification string with a timestamp.\"\n    expression: \"'New message received at ' + string(document.create_time)\"\n\nThe exact variables and functions that may be referenced within an expression\nare determined by the service that evaluates it. See the service\ndocumentation for additional information."}, "CreateBackupMetadata" {"id" "CreateBackupMetadata", "description" "Metadata type for the operation returned by\nCreateBackup.", "type" "object", "properties" {"progress" {"description" "The progress of the\nCreateBackup operation.", "$ref" "OperationProgress"}, "database" {"type" "string", "description" "The name of the database the backup is created from."}, "cancelTime" {"description" "The time at which cancellation of this operation was received.\nOperations.CancelOperation\nstarts asynchronous cancellation on a long-running operation. The server\nmakes a best effort to cancel the operation, but success is not guaranteed.\nClients can use\nOperations.GetOperation or\nother methods to check whether the cancellation succeeded or whether the\noperation completed despite cancellation. On successful cancellation,\nthe operation is not deleted; instead, it becomes an operation with\nan Operation.error value with a google.rpc.Status.code of 1,\ncorresponding to `Code.CANCELLED`.", "format" "google-datetime", "type" "string"}, "name" {"description" "The name of the backup being created.", "type" "string"}}}, "BatchCreateSessionsResponse" {"properties" {"session" {"description" "The freshly created sessions.", "type" "array", "items" {"$ref" "Session"}}}, "id" "BatchCreateSessionsResponse", "description" "The response for BatchCreateSessions.", "type" "object"}, "Write" {"description" "Arguments to insert, update, insert_or_update, and\nreplace operations.", "type" "object", "properties" {"table" {"description" "Required. The table whose rows will be written.", "type" "string"}, "columns" {"description" "The names of the columns in table to be written.\n\nThe list of columns must contain enough columns to allow\nCloud Spanner to derive values for all primary key columns in the\nrow(s) to be modified.", "type" "array", "items" {"type" "string"}}, "values" {"description" "The values to be written. `values` can contain more than one\nlist of values. If it does, then multiple rows are written, one\nfor each entry in `values`. Each list in `values` must have\nexactly as many entries as there are entries in columns\nabove. Sending multiple lists is equivalent to sending multiple\n`Mutation`s, each containing one `values` entry and repeating\ntable and columns. Individual values in each list are\nencoded as described here.", "type" "array", "items" {"type" "array", "items" {"type" "any"}}}}, "id" "Write"}, "StructType" {"type" "object", "properties" {"fields" {"type" "array", "items" {"$ref" "Field"}, "description" "The list of fields that make up this struct. Order is\nsignificant, because values of this struct type are represented as\nlists, where the order of field values matches the order of\nfields in the StructType. In turn, the order of fields\nmatches the order of columns in a read request, or the order of\nfields in the `SELECT` clause of a query."}}, "id" "StructType", "description" "`StructType` defines the fields of a STRUCT type."}, "ListOperationsResponse" {"id" "ListOperationsResponse", "description" "The response message for Operations.ListOperations.", "type" "object", "properties" {"nextPageToken" {"description" "The standard List next-page token.", "type" "string"}, "operations" {"description" "A list of operations that matches the specified filter in the request.", "type" "array", "items" {"$ref" "Operation"}}}}, "Type" {"properties" {"arrayElementType" {"$ref" "Type", "description" "If code == ARRAY, then `array_element_type`\nis the type of the array elements."}, "code" {"type" "string", "enumDescriptions" ["Not specified." "Encoded as JSON `true` or `false`." "Encoded as `string`, in decimal format." "Encoded as `number`, or the strings `\"NaN\"`, `\"Infinity\"`, or\n`\"-Infinity\"`." "Encoded as `string` in RFC 3339 timestamp format. The time zone\nmust be present, and must be `\"Z\"`.\n\nIf the schema has the column option\n`allow_commit_timestamp=true`, the placeholder string\n`\"spanner.commit_timestamp()\"` can be used to instruct the system\nto insert the commit timestamp associated with the transaction\ncommit." "Encoded as `string` in RFC 3339 date format." "Encoded as `string`." "Encoded as a base64-encoded `string`, as described in RFC 4648,\nsection 4." "Encoded as `list`, where the list elements are represented\naccording to\narray_element_type." "Encoded as `list`, where list element `i` is represented according\nto [struct_type.fields[i]][google.spanner.v1.StructType.fields]."], "enum" ["TYPE_CODE_UNSPECIFIED" "BOOL" "INT64" "FLOAT64" "TIMESTAMP" "DATE" "STRING" "BYTES" "ARRAY" "STRUCT"], "description" "Required. The TypeCode for this type."}, "structType" {"$ref" "StructType", "description" "If code == STRUCT, then `struct_type`\nprovides type information for the struct's fields."}}, "id" "Type", "description" "`Type` indicates the type of a Cloud Spanner value, as might be stored in a\ntable cell or returned from an SQL query.", "type" "object"}, "TransactionOptions" {"description" "# Transactions\n\n\nEach session can have at most one active transaction at a time. After the\nactive transaction is completed, the session can immediately be\nre-used for the next transaction. It is not necessary to create a\nnew session for each transaction.\n\n# Transaction Modes\n\nCloud Spanner supports three transaction modes:\n\n  1. Locking read-write. This type of transaction is the only way\n     to write data into Cloud Spanner. These transactions rely on\n     pessimistic locking and, if necessary, two-phase commit.\n     Locking read-write transactions may abort, requiring the\n     application to retry.\n\n  2. Snapshot read-only. This transaction type provides guaranteed\n     consistency across several reads, but does not allow\n     writes. Snapshot read-only transactions can be configured to\n     read at timestamps in the past. Snapshot read-only\n     transactions do not need to be committed.\n\n  3. Partitioned DML. This type of transaction is used to execute\n     a single Partitioned DML statement. Partitioned DML partitions\n     the key space and runs the DML statement over each partition\n     in parallel using separate, internal transactions that commit\n     independently. Partitioned DML transactions do not need to be\n     committed.\n\nFor transactions that only read, snapshot read-only transactions\nprovide simpler semantics and are almost always faster. In\nparticular, read-only transactions do not take locks, so they do\nnot conflict with read-write transactions. As a consequence of not\ntaking locks, they also do not abort, so retry loops are not needed.\n\nTransactions may only read/write data in a single database. They\nmay, however, read/write data in different tables within that\ndatabase.\n\n## Locking Read-Write Transactions\n\nLocking transactions may be used to atomically read-modify-write\ndata anywhere in a database. This type of transaction is externally\nconsistent.\n\nClients should attempt to minimize the amount of time a transaction\nis active. Faster transactions commit with higher probability\nand cause less contention. Cloud Spanner attempts to keep read locks\nactive as long as the transaction continues to do reads, and the\ntransaction has not been terminated by\nCommit or\nRollback.  Long periods of\ninactivity at the client may cause Cloud Spanner to release a\ntransaction's locks and abort it.\n\nConceptually, a read-write transaction consists of zero or more\nreads or SQL statements followed by\nCommit. At any time before\nCommit, the client can send a\nRollback request to abort the\ntransaction.\n\n### Semantics\n\nCloud Spanner can commit the transaction if all read locks it acquired\nare still valid at commit time, and it is able to acquire write\nlocks for all writes. Cloud Spanner can abort the transaction for any\nreason. If a commit attempt returns `ABORTED`, Cloud Spanner guarantees\nthat the transaction has not modified any user data in Cloud Spanner.\n\nUnless the transaction commits, Cloud Spanner makes no guarantees about\nhow long the transaction's locks were held for. It is an error to\nuse Cloud Spanner locks for any sort of mutual exclusion other than\nbetween Cloud Spanner transactions themselves.\n\n### Retrying Aborted Transactions\n\nWhen a transaction aborts, the application can choose to retry the\nwhole transaction again. To maximize the chances of successfully\ncommitting the retry, the client should execute the retry in the\nsame session as the original attempt. The original session's lock\npriority increases with each consecutive abort, meaning that each\nattempt has a slightly better chance of success than the previous.\n\nUnder some circumstances (e.g., many transactions attempting to\nmodify the same row(s)), a transaction can abort many times in a\nshort period before successfully committing. Thus, it is not a good\nidea to cap the number of retries a transaction can attempt;\ninstead, it is better to limit the total amount of wall time spent\nretrying.\n\n### Idle Transactions\n\nA transaction is considered idle if it has no outstanding reads or\nSQL queries and has not started a read or SQL query within the last 10\nseconds. Idle transactions can be aborted by Cloud Spanner so that they\ndon't hold on to locks indefinitely. In that case, the commit will\nfail with error `ABORTED`.\n\nIf this behavior is undesirable, periodically executing a simple\nSQL query in the transaction (e.g., `SELECT 1`) prevents the\ntransaction from becoming idle.\n\n## Snapshot Read-Only Transactions\n\nSnapshot read-only transactions provides a simpler method than\nlocking read-write transactions for doing several consistent\nreads. However, this type of transaction does not support writes.\n\nSnapshot transactions do not take locks. Instead, they work by\nchoosing a Cloud Spanner timestamp, then executing all reads at that\ntimestamp. Since they do not acquire locks, they do not block\nconcurrent read-write transactions.\n\nUnlike locking read-write transactions, snapshot read-only\ntransactions never abort. They can fail if the chosen read\ntimestamp is garbage collected; however, the default garbage\ncollection policy is generous enough that most applications do not\nneed to worry about this in practice.\n\nSnapshot read-only transactions do not need to call\nCommit or\nRollback (and in fact are not\npermitted to do so).\n\nTo execute a snapshot transaction, the client specifies a timestamp\nbound, which tells Cloud Spanner how to choose a read timestamp.\n\nThe types of timestamp bound are:\n\n  - Strong (the default).\n  - Bounded staleness.\n  - Exact staleness.\n\nIf the Cloud Spanner database to be read is geographically distributed,\nstale read-only transactions can execute more quickly than strong\nor read-write transaction, because they are able to execute far\nfrom the leader replica.\n\nEach type of timestamp bound is discussed in detail below.\n\n### Strong\n\nStrong reads are guaranteed to see the effects of all transactions\nthat have committed before the start of the read. Furthermore, all\nrows yielded by a single read are consistent with each other -- if\nany part of the read observes a transaction, all parts of the read\nsee the transaction.\n\nStrong reads are not repeatable: two consecutive strong read-only\ntransactions might return inconsistent results if there are\nconcurrent writes. If consistency across reads is required, the\nreads should be executed within a transaction or at an exact read\ntimestamp.\n\nSee TransactionOptions.ReadOnly.strong.\n\n### Exact Staleness\n\nThese timestamp bounds execute reads at a user-specified\ntimestamp. Reads at a timestamp are guaranteed to see a consistent\nprefix of the global transaction history: they observe\nmodifications done by all transactions with a commit timestamp <=\nthe read timestamp, and observe none of the modifications done by\ntransactions with a larger commit timestamp. They will block until\nall conflicting transactions that may be assigned commit timestamps\n<= the read timestamp have finished.\n\nThe timestamp can either be expressed as an absolute Cloud Spanner commit\ntimestamp or a staleness relative to the current time.\n\nThese modes do not require a \"negotiation phase\" to pick a\ntimestamp. As a result, they execute slightly faster than the\nequivalent boundedly stale concurrency modes. On the other hand,\nboundedly stale reads usually return fresher results.\n\nSee TransactionOptions.ReadOnly.read_timestamp and\nTransactionOptions.ReadOnly.exact_staleness.\n\n### Bounded Staleness\n\nBounded staleness modes allow Cloud Spanner to pick the read timestamp,\nsubject to a user-provided staleness bound. Cloud Spanner chooses the\nnewest timestamp within the staleness bound that allows execution\nof the reads at the closest available replica without blocking.\n\nAll rows yielded are consistent with each other -- if any part of\nthe read observes a transaction, all parts of the read see the\ntransaction. Boundedly stale reads are not repeatable: two stale\nreads, even if they use the same staleness bound, can execute at\ndifferent timestamps and thus return inconsistent results.\n\nBoundedly stale reads execute in two phases: the first phase\nnegotiates a timestamp among all replicas needed to serve the\nread. In the second phase, reads are executed at the negotiated\ntimestamp.\n\nAs a result of the two phase execution, bounded staleness reads are\nusually a little slower than comparable exact staleness\nreads. However, they are typically able to return fresher\nresults, and are more likely to execute at the closest replica.\n\nBecause the timestamp negotiation requires up-front knowledge of\nwhich rows will be read, it can only be used with single-use\nread-only transactions.\n\nSee TransactionOptions.ReadOnly.max_staleness and\nTransactionOptions.ReadOnly.min_read_timestamp.\n\n### Old Read Timestamps and Garbage Collection\n\nCloud Spanner continuously garbage collects deleted and overwritten data\nin the background to reclaim storage space. This process is known\nas \"version GC\". By default, version GC reclaims versions after they\nare one hour old. Because of this, Cloud Spanner cannot perform reads\nat read timestamps more than one hour in the past. This\nrestriction also applies to in-progress reads and/or SQL queries whose\ntimestamp become too old while executing. Reads and SQL queries with\ntoo-old read timestamps fail with the error `FAILED_PRECONDITION`.\n\n## Partitioned DML Transactions\n\nPartitioned DML transactions are used to execute DML statements with a\ndifferent execution strategy that provides different, and often better,\nscalability properties for large, table-wide operations than DML in a\nReadWrite transaction. Smaller scoped statements, such as an OLTP workload,\nshould prefer using ReadWrite transactions.\n\nPartitioned DML partitions the keyspace and runs the DML statement on each\npartition in separate, internal transactions. These transactions commit\nautomatically when complete, and run independently from one another.\n\nTo reduce lock contention, this execution strategy only acquires read locks\non rows that match the WHERE clause of the statement. Additionally, the\nsmaller per-partition transactions hold locks for less time.\n\nThat said, Partitioned DML is not a drop-in replacement for standard DML used\nin ReadWrite transactions.\n\n - The DML statement must be fully-partitionable. Specifically, the statement\n   must be expressible as the union of many statements which each access only\n   a single row of the table.\n\n - The statement is not applied atomically to all rows of the table. Rather,\n   the statement is applied atomically to partitions of the table, in\n   independent transactions. Secondary index rows are updated atomically\n   with the base table rows.\n\n - Partitioned DML does not guarantee exactly-once execution semantics\n   against a partition. The statement will be applied at least once to each\n   partition. It is strongly recommended that the DML statement should be\n   idempotent to avoid unexpected results. For instance, it is potentially\n   dangerous to run a statement such as\n   `UPDATE table SET column = column + 1` as it could be run multiple times\n   against some rows.\n\n - The partitions are committed automatically - there is no support for\n   Commit or Rollback. If the call returns an error, or if the client issuing\n   the ExecuteSql call dies, it is possible that some rows had the statement\n   executed on them successfully. It is also possible that statement was\n   never executed against other rows.\n\n - Partitioned DML transactions may only contain the execution of a single\n   DML statement via ExecuteSql or ExecuteStreamingSql.\n\n - If any error is encountered during the execution of the partitioned DML\n   operation (for instance, a UNIQUE INDEX violation, division by zero, or a\n   value that cannot be stored due to schema constraints), then the\n   operation is stopped at that point and an error is returned. It is\n   possible that at this point, some partitions have been committed (or even\n   committed multiple times), and other partitions have not been run at all.\n\nGiven the above, Partitioned DML is good fit for large, database-wide,\noperations that are idempotent, such as deleting old rows from a very large\ntable.", "type" "object", "properties" {"partitionedDml" {"description" "Partitioned DML transaction.\n\nAuthorization to begin a Partitioned DML transaction requires\n`spanner.databases.beginPartitionedDmlTransaction` permission\non the `session` resource.", "$ref" "PartitionedDml"}, "readWrite" {"description" "Transaction may write.\n\nAuthorization to begin a read-write transaction requires\n`spanner.databases.beginOrRollbackReadWriteTransaction` permission\non the `session` resource.", "$ref" "ReadWrite"}, "readOnly" {"description" "Transaction will not write.\n\nAuthorization to begin a read-only transaction requires\n`spanner.databases.beginReadOnlyTransaction` permission\non the `session` resource.", "$ref" "ReadOnly"}}, "id" "TransactionOptions"}, "ExecuteBatchDmlResponse" {"description" "The response for ExecuteBatchDml. Contains a list\nof ResultSet messages, one for each DML statement that has successfully\nexecuted, in the same order as the statements in the request. If a statement\nfails, the status in the response body identifies the cause of the failure.\n\nTo check for DML statements that failed, use the following approach:\n\n1. Check the status in the response message. The google.rpc.Code enum\n   value `OK` indicates that all statements were executed successfully.\n2. If the status was not `OK`, check the number of result sets in the\n   response. If the response contains `N` ResultSet messages, then\n   statement `N+1` in the request failed.\n\nExample 1:\n\n* Request: 5 DML statements, all executed successfully.\n* Response: 5 ResultSet messages, with the status `OK`.\n\nExample 2:\n\n* Request: 5 DML statements. The third statement has a syntax error.\n* Response: 2 ResultSet messages, and a syntax error (`INVALID_ARGUMENT`)\n  status. The number of ResultSet messages indicates that the third\n  statement failed, and the fourth and fifth statements were not executed.", "type" "object", "properties" {"resultSets" {"description" "One ResultSet for each statement in the request that ran successfully,\nin the same order as the statements in the request. Each ResultSet does\nnot contain any rows. The ResultSetStats in each ResultSet contain\nthe number of rows modified by the statement.\n\nOnly the first ResultSet in the response contains valid\nResultSetMetadata.", "type" "array", "items" {"$ref" "ResultSet"}}, "status" {"description" "If all DML statements are executed successfully, the status is `OK`.\nOtherwise, the error status of the first failed statement.", "$ref" "Status"}}, "id" "ExecuteBatchDmlResponse"}, "ListSessionsResponse" {"properties" {"nextPageToken" {"description" "`next_page_token` can be sent in a subsequent\nListSessions call to fetch more of the matching\nsessions.", "type" "string"}, "sessions" {"type" "array", "items" {"$ref" "Session"}, "description" "The list of requested sessions."}}, "id" "ListSessionsResponse", "description" "The response for ListSessions.", "type" "object"}, "ReplicaInfo" {"type" "object", "properties" {"type" {"enumDescriptions" ["Not specified." "Read-write replicas support both reads and writes. These replicas:\n\n* Maintain a full copy of your data.\n* Serve reads.\n* Can vote whether to commit a write.\n* Participate in leadership election.\n* Are eligible to become a leader." "Read-only replicas only support reads (not writes). Read-only replicas:\n\n* Maintain a full copy of your data.\n* Serve reads.\n* Do not participate in voting to commit writes.\n* Are not eligible to become a leader." "Witness replicas don't support reads but do participate in voting to\ncommit writes. Witness replicas:\n\n* Do not maintain a full copy of data.\n* Do not serve reads.\n* Vote whether to commit writes.\n* Participate in leader election but are not eligible to become leader."], "enum" ["TYPE_UNSPECIFIED" "READ_WRITE" "READ_ONLY" "WITNESS"], "description" "The type of replica.", "type" "string"}, "defaultLeaderLocation" {"description" "If true, this location is designated as the default leader location where\nleader replicas are placed. See the [region types\ndocumentation](https://cloud.google.com/spanner/docs/instances#region_types)\nfor more details.", "type" "boolean"}, "location" {"description" "The location of the serving resources, e.g. \"us-central1\".", "type" "string"}}, "id" "ReplicaInfo"}, "PartitionResponse" {"description" "The response for PartitionQuery\nor PartitionRead", "type" "object", "properties" {"transaction" {"$ref" "Transaction", "description" "Transaction created by this request."}, "partitions" {"type" "array", "items" {"$ref" "Partition"}, "description" "Partitions created by this request."}}, "id" "PartitionResponse"}, "PartitionQueryRequest" {"id" "PartitionQueryRequest", "description" "The request for PartitionQuery", "type" "object", "properties" {"paramTypes" {"type" "object", "additionalProperties" {"$ref" "Type"}, "description" "It is not always possible for Cloud Spanner to infer the right SQL type\nfrom a JSON value.  For example, values of type `BYTES` and values\nof type `STRING` both appear in params as JSON strings.\n\nIn these cases, `param_types` can be used to specify the exact\nSQL type for some or all of the SQL query parameters. See the\ndefinition of Type for more information\nabout SQL types."}, "sql" {"type" "string", "description" "Required. The query request to generate partitions for. The request will fail if\nthe query is not root partitionable. The query plan of a root\npartitionable query has a single distributed union operator. A distributed\nunion operator conceptually divides one or more tables into multiple\nsplits, remotely evaluates a subquery independently on each split, and\nthen unions all results.\n\nThis must not contain DML commands, such as INSERT, UPDATE, or\nDELETE. Use ExecuteStreamingSql with a\nPartitionedDml transaction for large, partition-friendly DML operations."}, "transaction" {"description" "Read only snapshot transactions are supported, read/write and single use\ntransactions are not.", "$ref" "TransactionSelector"}, "partitionOptions" {"$ref" "PartitionOptions", "description" "Additional options that affect how many partitions are created."}, "params" {"additionalProperties" {"description" "Properties of the object.", "type" "any"}, "description" "Parameter names and values that bind to placeholders in the SQL string.\n\nA parameter placeholder consists of the `@` character followed by the\nparameter name (for example, `@firstName`). Parameter names can contain\nletters, numbers, and underscores.\n\nParameters can appear anywhere that a literal value is expected.  The same\nparameter name can be used more than once, for example:\n\n`\"WHERE id > @msg_id AND id < @msg_id + 100\"`\n\nIt is an error to execute a SQL statement with unbound parameters.", "type" "object"}}}, "RestoreDatabaseMetadata" {"description" "Metadata type for the long-running operation returned by\nRestoreDatabase.", "type" "object", "properties" {"progress" {"$ref" "OperationProgress", "description" "The progress of the\nRestoreDatabase\noperation."}, "cancelTime" {"description" "The time at which cancellation of this operation was received.\nOperations.CancelOperation\nstarts asynchronous cancellation on a long-running operation. The server\nmakes a best effort to cancel the operation, but success is not guaranteed.\nClients can use\nOperations.GetOperation or\nother methods to check whether the cancellation succeeded or whether the\noperation completed despite cancellation. On successful cancellation,\nthe operation is not deleted; instead, it becomes an operation with\nan Operation.error value with a\ngoogle.rpc.Status.code of 1, corresponding to `Code.CANCELLED`.", "format" "google-datetime", "type" "string"}, "sourceType" {"description" "The type of the restore source.", "type" "string", "enumDescriptions" ["No restore associated." "A backup was used as the source of the restore."], "enum" ["TYPE_UNSPECIFIED" "BACKUP"]}, "backupInfo" {"$ref" "BackupInfo", "description" "Information about the backup used to restore the database."}, "name" {"description" "Name of the database being created and restored to.", "type" "string"}, "optimizeDatabaseOperationName" {"description" "If exists, the name of the long-running operation that will be used to\ntrack the post-restore optimization process to optimize the performance of\nthe restored database, and remove the dependency on the restore source.\nThe name is of the form\n`projects/<project>/instances/<instance>/databases/<database>/operations/<operation>`\nwhere the <database> is the name of database being created and restored to.\nThe metadata type of the  long-running operation is\nOptimizeRestoredDatabaseMetadata. This long-running operation will be\nautomatically created by the system after the RestoreDatabase long-running\noperation completes successfully. This operation will not be created if the\nrestore was not successful.", "type" "string"}}, "id" "RestoreDatabaseMetadata"}, "ShortRepresentation" {"description" "Condensed representation of a node and its subtree. Only present for\n`SCALAR` PlanNode(s).", "type" "object", "properties" {"description" {"description" "A string representation of the expression subtree rooted at this node.", "type" "string"}, "subqueries" {"additionalProperties" {"format" "int32", "type" "integer"}, "description" "A mapping of (subquery variable name) -> (subquery node id) for cases\nwhere the `description` string of this node references a `SCALAR`\nsubquery contained in the expression subtree rooted at this node. The\nreferenced `SCALAR` subquery may not necessarily be a direct child of\nthis node.", "type" "object"}}, "id" "ShortRepresentation"}, "Binding" {"type" "object", "properties" {"role" {"description" "Role that is assigned to `members`.\nFor example, `roles/viewer`, `roles/editor`, or `roles/owner`.", "type" "string"}, "condition" {"$ref" "Expr", "description" "The condition that is associated with this binding.\nNOTE: An unsatisfied condition will not allow user access via current\nbinding. Different bindings, including their conditions, are examined\nindependently."}, "members" {"type" "array", "items" {"type" "string"}, "description" "Specifies the identities requesting access for a Cloud Platform resource.\n`members` can have the following values:\n\n* `allUsers`: A special identifier that represents anyone who is\n   on the internet; with or without a Google account.\n\n* `allAuthenticatedUsers`: A special identifier that represents anyone\n   who is authenticated with a Google account or a service account.\n\n* `user:{emailid}`: An email address that represents a specific Google\n   account. For example, `alice@example.com` .\n\n\n* `serviceAccount:{emailid}`: An email address that represents a service\n   account. For example, `my-other-app@appspot.gserviceaccount.com`.\n\n* `group:{emailid}`: An email address that represents a Google group.\n   For example, `admins@example.com`.\n\n* `deleted:user:{emailid}?uid={uniqueid}`: An email address (plus unique\n   identifier) representing a user that has been recently deleted. For\n   example, `alice@example.com?uid=123456789012345678901`. If the user is\n   recovered, this value reverts to `user:{emailid}` and the recovered user\n   retains the role in the binding.\n\n* `deleted:serviceAccount:{emailid}?uid={uniqueid}`: An email address (plus\n   unique identifier) representing a service account that has been recently\n   deleted. For example,\n   `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`.\n   If the service account is undeleted, this value reverts to\n   `serviceAccount:{emailid}` and the undeleted service account retains the\n   role in the binding.\n\n* `deleted:group:{emailid}?uid={uniqueid}`: An email address (plus unique\n   identifier) representing a Google group that has been recently\n   deleted. For example, `admins@example.com?uid=123456789012345678901`. If\n   the group is recovered, this value reverts to `group:{emailid}` and the\n   recovered group retains the role in the binding.\n\n\n* `domain:{domain}`: The G Suite domain (primary) that represents all the\n   users of that domain. For example, `google.com` or `example.com`.\n\n"}}, "id" "Binding", "description" "Associates `members` with a `role`."}, "BackupInfo" {"description" "Information about a backup.", "type" "object", "properties" {"backup" {"description" "Name of the backup.", "type" "string"}, "sourceDatabase" {"description" "Name of the database the backup was created from.", "type" "string"}, "createTime" {"description" "The backup contains an externally consistent copy of `source_database` at\nthe timestamp specified by `create_time`.", "format" "google-datetime", "type" "string"}}, "id" "BackupInfo"}, "Statement" {"id" "Statement", "description" "A single DML statement.", "type" "object", "properties" {"paramTypes" {"description" "It is not always possible for Cloud Spanner to infer the right SQL type\nfrom a JSON value.  For example, values of type `BYTES` and values\nof type `STRING` both appear in params as JSON strings.\n\nIn these cases, `param_types` can be used to specify the exact\nSQL type for some or all of the SQL statement parameters. See the\ndefinition of Type for more information\nabout SQL types.", "type" "object", "additionalProperties" {"$ref" "Type"}}, "sql" {"description" "Required. The DML string.", "type" "string"}, "params" {"type" "object", "additionalProperties" {"description" "Properties of the object.", "type" "any"}, "description" "Parameter names and values that bind to placeholders in the DML string.\n\nA parameter placeholder consists of the `@` character followed by the\nparameter name (for example, `@firstName`). Parameter names can contain\nletters, numbers, and underscores.\n\nParameters can appear anywhere that a literal value is expected.  The\nsame parameter name can be used more than once, for example:\n\n`\"WHERE id > @msg_id AND id < @msg_id + 100\"`\n\nIt is an error to execute a SQL statement with unbound parameters."}}}, "OperationProgress" {"type" "object", "properties" {"endTime" {"type" "string", "description" "If set, the time at which this operation failed or was completed\nsuccessfully.", "format" "google-datetime"}, "startTime" {"description" "Time the request was received.", "format" "google-datetime", "type" "string"}, "progressPercent" {"description" "Percent completion of the operation.\nValues are between 0 and 100 inclusive.", "format" "int32", "type" "integer"}}, "id" "OperationProgress", "description" "Encapsulates progress related information for a Cloud Spanner long\nrunning operation."}, "ResultSetStats" {"type" "object", "properties" {"rowCountLowerBound" {"description" "Partitioned DML does not offer exactly-once semantics, so it\nreturns a lower bound of the rows modified.", "format" "int64", "type" "string"}, "queryPlan" {"description" "QueryPlan for the query associated with this result.", "$ref" "QueryPlan"}, "rowCountExact" {"description" "Standard DML returns an exact count of rows that were modified.", "format" "int64", "type" "string"}, "queryStats" {"additionalProperties" {"description" "Properties of the object.", "type" "any"}, "description" "Aggregated statistics from the execution of the query. Only present when\nthe query is profiled. For example, a query could return the statistics as\nfollows:\n\n    {\n      \"rows_returned\": \"3\",\n      \"elapsed_time\": \"1.22 secs\",\n      \"cpu_time\": \"1.19 secs\"\n    }", "type" "object"}}, "id" "ResultSetStats", "description" "Additional statistics about a ResultSet or PartialResultSet."}, "ExecuteSqlRequest" {"description" "The request for ExecuteSql and\nExecuteStreamingSql.", "type" "object", "properties" {"paramTypes" {"description" "It is not always possible for Cloud Spanner to infer the right SQL type\nfrom a JSON value.  For example, values of type `BYTES` and values\nof type `STRING` both appear in params as JSON strings.\n\nIn these cases, `param_types` can be used to specify the exact\nSQL type for some or all of the SQL statement parameters. See the\ndefinition of Type for more information\nabout SQL types.", "type" "object", "additionalProperties" {"$ref" "Type"}}, "queryMode" {"enumDescriptions" ["The default mode. Only the statement results are returned." "This mode returns only the query plan, without any results or\nexecution statistics information." "This mode returns both the query plan and the execution statistics along\nwith the results."], "enum" ["NORMAL" "PLAN" "PROFILE"], "description" "Used to control the amount of debugging information returned in\nResultSetStats. If partition_token is set, query_mode can only\nbe set to QueryMode.NORMAL.", "type" "string"}, "transaction" {"$ref" "TransactionSelector", "description" "The transaction to use.\n\nFor queries, if none is provided, the default is a temporary read-only\ntransaction with strong concurrency.\n\nStandard DML statements require a read-write transaction. To protect\nagainst replays, single-use transactions are not supported.  The caller\nmust either supply an existing transaction ID or begin a new transaction.\n\nPartitioned DML requires an existing Partitioned DML transaction ID."}, "params" {"additionalProperties" {"description" "Properties of the object.", "type" "any"}, "description" "Parameter names and values that bind to placeholders in the SQL string.\n\nA parameter placeholder consists of the `@` character followed by the\nparameter name (for example, `@firstName`). Parameter names can contain\nletters, numbers, and underscores.\n\nParameters can appear anywhere that a literal value is expected.  The same\nparameter name can be used more than once, for example:\n\n`\"WHERE id > @msg_id AND id < @msg_id + 100\"`\n\nIt is an error to execute a SQL statement with unbound parameters.", "type" "object"}, "resumeToken" {"description" "If this request is resuming a previously interrupted SQL statement\nexecution, `resume_token` should be copied from the last\nPartialResultSet yielded before the interruption. Doing this\nenables the new SQL statement execution to resume where the last one left\noff. The rest of the request parameters must exactly match the\nrequest that yielded this token.", "format" "byte", "type" "string"}, "partitionToken" {"description" "If present, results will be restricted to the specified partition\npreviously created using PartitionQuery().  There must be an exact\nmatch for the values of fields common to this message and the\nPartitionQueryRequest message used to create this partition_token.", "format" "byte", "type" "string"}, "sql" {"description" "Required. The SQL string.", "type" "string"}, "queryOptions" {"description" "Query optimizer configuration to use for the given query.", "$ref" "QueryOptions"}, "seqno" {"description" "A per-transaction sequence number used to identify this request. This field\nmakes each request idempotent such that if the request is received multiple\ntimes, at most one will succeed.\n\nThe sequence number must be monotonically increasing within the\ntransaction. If a request arrives for the first time with an out-of-order\nsequence number, the transaction may be aborted. Replays of previously\nhandled requests will yield the same response as the first execution.\n\nRequired for DML statements. Ignored for queries.", "format" "int64", "type" "string"}}, "id" "ExecuteSqlRequest"}, "TransactionSelector" {"id" "TransactionSelector", "description" "This message is used to select the transaction in which a\nRead or\nExecuteSql call runs.\n\nSee TransactionOptions for more information about transactions.", "type" "object", "properties" {"singleUse" {"$ref" "TransactionOptions", "description" "Execute the read or SQL query in a temporary transaction.\nThis is the most efficient way to execute a transaction that\nconsists of a single SQL query."}, "begin" {"description" "Begin a new transaction and execute this read or SQL query in\nit. The transaction ID of the new transaction is returned in\nResultSetMetadata.transaction, which is a Transaction.", "$ref" "TransactionOptions"}, "id" {"description" "Execute the read or SQL query in a previously-started transaction.", "format" "byte", "type" "string"}}}, "Operation" {"description" "This resource represents a long-running operation that is the result of a\nnetwork API call.", "type" "object", "properties" {"response" {"description" "The normal response of the operation in case of success.  If the original\nmethod returns no data on success, such as `Delete`, the response is\n`google.protobuf.Empty`.  If the original method is standard\n`Get`/`Create`/`Update`, the response should be the resource.  For other\nmethods, the response should have the type `XxxResponse`, where `Xxx`\nis the original method name.  For example, if the original method name\nis `TakeSnapshot()`, the inferred response type is\n`TakeSnapshotResponse`.", "type" "object", "additionalProperties" {"description" "Properties of the object. Contains field @type with type URL.", "type" "any"}}, "name" {"description" "The server-assigned name, which is only unique within the same service that\noriginally returns it. If you use the default HTTP mapping, the\n`name` should be a resource name ending with `operations/{unique_id}`.", "type" "string"}, "error" {"description" "The error result of the operation in case of failure or cancellation.", "$ref" "Status"}, "metadata" {"additionalProperties" {"description" "Properties of the object. Contains field @type with type URL.", "type" "any"}, "description" "Service-specific metadata associated with the operation.  It typically\ncontains progress information and common metadata such as create time.\nSome services might not provide such metadata.  Any method that returns a\nlong-running operation should document the metadata type, if any.", "type" "object"}, "done" {"description" "If the value is `false`, it means the operation is still in progress.\nIf `true`, the operation is completed, and either `error` or `response` is\navailable.", "type" "boolean"}}, "id" "Operation"}, "RestoreInfo" {"id" "RestoreInfo", "description" "Information about the database restore.", "type" "object", "properties" {"sourceType" {"description" "The type of the restore source.", "type" "string", "enumDescriptions" ["No restore associated." "A backup was used as the source of the restore."], "enum" ["TYPE_UNSPECIFIED" "BACKUP"]}, "backupInfo" {"$ref" "BackupInfo", "description" "Information about the backup used to restore the database. The backup\nmay no longer exist."}}}, "Status" {"description" "The `Status` type defines a logical error model that is suitable for\ndifferent programming environments, including REST APIs and RPC APIs. It is\nused by [gRPC](https://github.com/grpc). Each `Status` message contains\nthree pieces of data: error code, error message, and error details.\n\nYou can find out more about this error model and how to work with it in the\n[API Design Guide](https://cloud.google.com/apis/design/errors).", "type" "object", "properties" {"details" {"description" "A list of messages that carry the error details.  There is a common set of\nmessage types for APIs to use.", "type" "array", "items" {"additionalProperties" {"description" "Properties of the object. Contains field @type with type URL.", "type" "any"}, "type" "object"}}, "code" {"description" "The status code, which should be an enum value of google.rpc.Code.", "format" "int32", "type" "integer"}, "message" {"description" "A developer-facing error message, which should be in English. Any\nuser-facing error message should be localized and sent in the\ngoogle.rpc.Status.details field, or localized by the client.", "type" "string"}}, "id" "Status"}, "PlanNode" {"description" "Node information for nodes appearing in a QueryPlan.plan_nodes.", "type" "object", "properties" {"metadata" {"description" "Attributes relevant to the node contained in a group of key-value pairs.\nFor example, a Parameter Reference node could have the following\ninformation in its metadata:\n\n    {\n      \"parameter_reference\": \"param1\",\n      \"parameter_type\": \"array\"\n    }", "type" "object", "additionalProperties" {"description" "Properties of the object.", "type" "any"}}, "executionStats" {"description" "The execution statistics associated with the node, contained in a group of\nkey-value pairs. Only present if the plan was returned as a result of a\nprofile query. For example, number of executions, number of rows/time per\nexecution etc.", "type" "object", "additionalProperties" {"description" "Properties of the object.", "type" "any"}}, "shortRepresentation" {"$ref" "ShortRepresentation", "description" "Condensed representation for SCALAR nodes."}, "index" {"description" "The `PlanNode`'s index in node list.", "format" "int32", "type" "integer"}, "kind" {"enumDescriptions" ["Not specified." "Denotes a Relational operator node in the expression tree. Relational\noperators represent iterative processing of rows during query execution.\nFor example, a `TableScan` operation that reads rows from a table." "Denotes a Scalar node in the expression tree. Scalar nodes represent\nnon-iterable entities in the query plan. For example, constants or\narithmetic operators appearing inside predicate expressions or references\nto column names."], "enum" ["KIND_UNSPECIFIED" "RELATIONAL" "SCALAR"], "description" "Used to determine the type of node. May be needed for visualizing\ndifferent kinds of nodes differently. For example, If the node is a\nSCALAR node, it will have a condensed representation\nwhich can be used to directly embed a description of the node in its\nparent.", "type" "string"}, "displayName" {"description" "The display name for the node.", "type" "string"}, "childLinks" {"description" "List of child node `index`es and their relationship to this parent.", "type" "array", "items" {"$ref" "ChildLink"}}}, "id" "PlanNode"}, "OptimizeRestoredDatabaseMetadata" {"type" "object", "properties" {"name" {"description" "Name of the restored database being optimized.", "type" "string"}, "progress" {"description" "The progress of the post-restore optimizations.", "$ref" "OperationProgress"}}, "id" "OptimizeRestoredDatabaseMetadata", "description" "Metadata type for the long-running operation used to track the progress\nof optimizations performed on a newly restored database. This long-running\noperation is automatically created by the system after the successful\ncompletion of a database restore, and cannot be cancelled."}, "QueryOptions" {"type" "object", "properties" {"optimizerVersion" {"description" "An option to control the selection of optimizer version.\n\nThis parameter allows individual queries to pick different query\noptimizer versions.\n\nSpecifying \"latest\" as a value instructs Cloud Spanner to use the\nlatest supported query optimizer version. If not specified, Cloud Spanner\nuses optimizer version set at the database level options. Any other\npositive integer (from the list of supported optimizer versions)\noverrides the default optimizer version for query execution.\nThe list of supported optimizer versions can be queried from\nSPANNER_SYS.SUPPORTED_OPTIMIZER_VERSIONS. Executing a SQL statement\nwith an invalid optimizer version will fail with a syntax error\n(`INVALID_ARGUMENT`) status.\n\nThe `optimizer_version` statement hint has precedence over this setting.", "type" "string"}}, "id" "QueryOptions", "description" "Query optimizer configuration."}, "Delete" {"description" "Arguments to delete operations.", "type" "object", "properties" {"table" {"description" "Required. The table whose rows will be deleted.", "type" "string"}, "keySet" {"$ref" "KeySet", "description" "Required. The primary keys of the rows within table to delete.  The\nprimary keys must be specified in the order in which they appear in the\n`PRIMARY KEY()` clause of the table's equivalent DDL statement (the DDL\nstatement used to create the table).\nDelete is idempotent. The transaction will succeed even if some or all\nrows do not exist."}}, "id" "Delete"}, "GetPolicyOptions" {"description" "Encapsulates settings provided to GetIamPolicy.", "type" "object", "properties" {"requestedPolicyVersion" {"type" "integer", "description" "Optional. The policy format version to be returned.\n\nValid values are 0, 1, and 3. Requests specifying an invalid value will be\nrejected.\n\nRequests for policies with any conditional bindings must specify version 3.\nPolicies without any conditional bindings may specify any valid value or\nleave the field unset.", "format" "int32"}}, "id" "GetPolicyOptions"}, "ExecuteBatchDmlRequest" {"description" "The request for ExecuteBatchDml.", "type" "object", "properties" {"statements" {"type" "array", "items" {"$ref" "Statement"}, "description" "Required. The list of statements to execute in this batch. Statements are executed\nserially, such that the effects of statement `i` are visible to statement\n`i+1`. Each statement must be a DML statement. Execution stops at the\nfirst failed statement; the remaining statements are not executed.\n\nCallers must provide at least one statement."}, "transaction" {"$ref" "TransactionSelector", "description" "Required. The transaction to use. Must be a read-write transaction.\n\nTo protect against replays, single-use transactions are not supported. The\ncaller must either supply an existing transaction ID or begin a new\ntransaction."}, "seqno" {"description" "Required. A per-transaction sequence number used to identify this request. This field\nmakes each request idempotent such that if the request is received multiple\ntimes, at most one will succeed.\n\nThe sequence number must be monotonically increasing within the\ntransaction. If a request arrives for the first time with an out-of-order\nsequence number, the transaction may be aborted. Replays of previously\nhandled requests will yield the same response as the first execution.", "format" "int64", "type" "string"}}, "id" "ExecuteBatchDmlRequest"}, "UpdateInstanceRequest" {"description" "The request for UpdateInstance.", "type" "object", "properties" {"instance" {"$ref" "Instance", "description" "Required. The instance to update, which must always include the instance\nname.  Otherwise, only fields mentioned in field_mask need be included."}, "fieldMask" {"description" "Required. A mask specifying which fields in Instance should be updated.\nThe field mask must always be specified; this prevents any future fields in\nInstance from being erased accidentally by clients that do not know\nabout them.", "format" "google-fieldmask", "type" "string"}}, "id" "UpdateInstanceRequest"}, "BatchCreateSessionsRequest" {"type" "object", "properties" {"sessionTemplate" {"$ref" "Session", "description" "Parameters to be applied to each created session."}, "sessionCount" {"description" "Required. The number of sessions to be created in this batch call.\nThe API may return fewer than the requested number of sessions. If a\nspecific number of sessions are desired, the client can make additional\ncalls to BatchCreateSessions (adjusting\nsession_count as necessary).", "format" "int32", "type" "integer"}}, "id" "BatchCreateSessionsRequest", "description" "The request for BatchCreateSessions."}, "RollbackRequest" {"description" "The request for Rollback.", "type" "object", "properties" {"transactionId" {"type" "string", "description" "Required. The transaction to roll back.", "format" "byte"}}, "id" "RollbackRequest"}, "TestIamPermissionsResponse" {"description" "Response message for `TestIamPermissions` method.", "type" "object", "properties" {"permissions" {"description" "A subset of `TestPermissionsRequest.permissions` that the caller is\nallowed.", "type" "array", "items" {"type" "string"}}}, "id" "TestIamPermissionsResponse"}, "UpdateDatabaseDdlMetadata" {"description" "Metadata type for the operation returned by\nUpdateDatabaseDdl.", "type" "object", "properties" {"database" {"description" "The database being modified.", "type" "string"}, "statements" {"description" "For an update this list contains all the statements. For an\nindividual statement, this list contains only that statement.", "type" "array", "items" {"type" "string"}}, "commitTimestamps" {"description" "Reports the commit timestamps of all statements that have\nsucceeded so far, where `commit_timestamps[i]` is the commit\ntimestamp for the statement `statements[i]`.", "type" "array", "items" {"format" "google-datetime", "type" "string"}}}, "id" "UpdateDatabaseDdlMetadata"}, "ChildLink" {"description" "Metadata associated with a parent-child relationship appearing in a\nPlanNode.", "type" "object", "properties" {"type" {"description" "The type of the link. For example, in Hash Joins this could be used to\ndistinguish between the build child and the probe child, or in the case\nof the child being an output variable, to represent the tag associated\nwith the output variable.", "type" "string"}, "childIndex" {"description" "The node to which the link points.", "format" "int32", "type" "integer"}, "variable" {"description" "Only present if the child node is SCALAR and corresponds\nto an output variable of the parent node. The field carries the name of\nthe output variable.\nFor example, a `TableScan` operator that reads rows from a table will\nhave child links to the `SCALAR` nodes representing the output variables\ncreated for each column that is read by the operator. The corresponding\n`variable` fields will be set to the variable names assigned to the\ncolumns.", "type" "string"}}, "id" "ChildLink"}, "ListBackupsResponse" {"description" "The response for ListBackups.", "type" "object", "properties" {"backups" {"type" "array", "items" {"$ref" "Backup"}, "description" "The list of matching backups. Backups returned are ordered by `create_time`\nin descending order, starting from the most recent `create_time`."}, "nextPageToken" {"description" "`next_page_token` can be sent in a subsequent\nListBackups call to fetch more\nof the matching backups.", "type" "string"}}, "id" "ListBackupsResponse"}, "CommitRequest" {"type" "object", "properties" {"singleUseTransaction" {"description" "Execute mutations in a temporary transaction. Note that unlike\ncommit of a previously-started transaction, commit with a\ntemporary transaction is non-idempotent. That is, if the\n`CommitRequest` is sent to Cloud Spanner more than once (for\ninstance, due to retries in the application, or in the\ntransport library), it is possible that the mutations are\nexecuted more than once. If this is undesirable, use\nBeginTransaction and\nCommit instead.", "$ref" "TransactionOptions"}, "mutations" {"type" "array", "items" {"$ref" "Mutation"}, "description" "The mutations to be executed when this transaction commits. All\nmutations are applied atomically, in the order they appear in\nthis list."}, "transactionId" {"description" "Commit a previously-started transaction.", "format" "byte", "type" "string"}}, "id" "CommitRequest", "description" "The request for Commit."}, "ReadRequest" {"description" "The request for Read and\nStreamingRead.", "type" "object", "properties" {"transaction" {"$ref" "TransactionSelector", "description" "The transaction to use. If none is provided, the default is a\ntemporary read-only transaction with strong concurrency."}, "resumeToken" {"description" "If this request is resuming a previously interrupted read,\n`resume_token` should be copied from the last\nPartialResultSet yielded before the interruption. Doing this\nenables the new read to resume where the last read left off. The\nrest of the request parameters must exactly match the request\nthat yielded this token.", "format" "byte", "type" "string"}, "partitionToken" {"description" "If present, results will be restricted to the specified partition\npreviously created using PartitionRead().    There must be an exact\nmatch for the values of fields common to this message and the\nPartitionReadRequest message used to create this partition_token.", "format" "byte", "type" "string"}, "table" {"type" "string", "description" "Required. The name of the table in the database to be read."}, "limit" {"description" "If greater than zero, only the first `limit` rows are yielded. If `limit`\nis zero, the default is no limit. A limit cannot be specified if\n`partition_token` is set.", "format" "int64", "type" "string"}, "index" {"description" "If non-empty, the name of an index on table. This index is\nused instead of the table primary key when interpreting key_set\nand sorting result rows. See key_set for further information.", "type" "string"}, "keySet" {"$ref" "KeySet", "description" "Required. `key_set` identifies the rows to be yielded. `key_set` names the\nprimary keys of the rows in table to be yielded, unless index\nis present. If index is present, then key_set instead names\nindex keys in index.\n\nIf the partition_token field is empty, rows are yielded\nin table primary key order (if index is empty) or index key order\n(if index is non-empty).  If the partition_token field is not\nempty, rows will be yielded in an unspecified order.\n\nIt is not an error for the `key_set` to name rows that do not\nexist in the database. Read yields nothing for nonexistent rows."}, "columns" {"description" "Required. The columns of table to be returned for each row matching\nthis request.", "type" "array", "items" {"type" "string"}}}, "id" "ReadRequest"}, "BeginTransactionRequest" {"description" "The request for BeginTransaction.", "type" "object", "properties" {"options" {"description" "Required. Options for the new transaction.", "$ref" "TransactionOptions"}}, "id" "BeginTransactionRequest"}, "ListInstancesResponse" {"description" "The response for ListInstances.", "type" "object", "properties" {"instances" {"description" "The list of requested instances.", "type" "array", "items" {"$ref" "Instance"}}, "nextPageToken" {"description" "`next_page_token` can be sent in a subsequent\nListInstances call to fetch more\nof the matching instances.", "type" "string"}}, "id" "ListInstancesResponse"}, "Backup" {"description" "A backup of a Cloud Spanner database.", "type" "object", "properties" {"referencingDatabases" {"description" "Output only. The names of the restored databases that reference the backup.\nThe database names are of\nthe form `projects/<project>/instances/<instance>/databases/<database>`.\nReferencing databases may exist in different instances. The existence of\nany referencing database prevents the backup from being deleted. When a\nrestored database from the backup enters the `READY` state, the reference\nto the backup is removed.", "type" "array", "items" {"type" "string"}}, "sizeBytes" {"description" "Output only. Size of the backup in bytes.", "format" "int64", "type" "string"}, "database" {"description" "Required for the CreateBackup operation.\nName of the database from which this backup was\ncreated. This needs to be in the same instance as the backup.\nValues are of the form\n`projects/<project>/instances/<instance>/databases/<database>`.", "type" "string"}, "createTime" {"description" "Output only. The backup will contain an externally consistent\ncopy of the database at the timestamp specified by\n`create_time`. `create_time` is approximately the time the\nCreateBackup request is received.", "format" "google-datetime", "type" "string"}, "expireTime" {"description" "Required for the CreateBackup\noperation. The expiration time of the backup, with microseconds\ngranularity that must be at least 6 hours and at most 366 days\nfrom the time the CreateBackup request is processed. Once the `expire_time`\nhas passed, the backup is eligible to be automatically deleted by Cloud\nSpanner to free the resources used by the backup.", "format" "google-datetime", "type" "string"}, "state" {"enum" ["STATE_UNSPECIFIED" "CREATING" "READY"], "description" "Output only. The current state of the backup.", "type" "string", "enumDescriptions" ["Not specified." "The pending backup is still being created. Operations on the\nbackup may fail with `FAILED_PRECONDITION` in this state." "The backup is complete and ready for use."]}, "name" {"description" "Output only for the CreateBackup operation.\nRequired for the UpdateBackup operation.\n\nA globally unique identifier for the backup which cannot be\nchanged. Values are of the form\n`projects/<project>/instances/<instance>/backups/a-z*[a-z0-9]`\nThe final segment of the name must be between 2 and 60 characters\nin length.\n\nThe backup is stored in the location(s) specified in the instance\nconfiguration of the instance containing the backup, identified\nby the prefix of the backup name of the form\n`projects/<project>/instances/<instance>`.", "type" "string"}}, "id" "Backup"}, "ResultSet" {"description" "Results from Read or\nExecuteSql.", "type" "object", "properties" {"stats" {"$ref" "ResultSetStats", "description" "Query plan and execution statistics for the SQL statement that\nproduced this result set. These can be requested by setting\nExecuteSqlRequest.query_mode.\nDML statements always produce stats containing the number of rows\nmodified, unless executed using the\nExecuteSqlRequest.QueryMode.PLAN ExecuteSqlRequest.query_mode.\nOther fields may or may not be populated, based on the\nExecuteSqlRequest.query_mode."}, "rows" {"description" "Each element in `rows` is a row whose format is defined by\nmetadata.row_type. The ith element\nin each row matches the ith field in\nmetadata.row_type. Elements are\nencoded based on type as described\nhere.", "type" "array", "items" {"type" "array", "items" {"type" "any"}}}, "metadata" {"description" "Metadata about the result set, such as row type information.", "$ref" "ResultSetMetadata"}}, "id" "ResultSet"}, "ReadOnly" {"description" "Message type to initiate a read-only transaction.", "type" "object", "properties" {"readTimestamp" {"description" "Executes all reads at the given timestamp. Unlike other modes,\nreads at a specific timestamp are repeatable; the same read at\nthe same timestamp always returns the same data. If the\ntimestamp is in the future, the read will block until the\nspecified timestamp, modulo the read's deadline.\n\nUseful for large scale consistent reads such as mapreduces, or\nfor coordinating many reads against a consistent snapshot of the\ndata.\n\nA timestamp in RFC3339 UTC \\\"Zulu\\\" format, accurate to nanoseconds.\nExample: `\"2014-10-02T15:01:23.045123456Z\"`.", "format" "google-datetime", "type" "string"}, "maxStaleness" {"description" "Read data at a timestamp >= `NOW - max_staleness`\nseconds. Guarantees that all writes that have committed more\nthan the specified number of seconds ago are visible. Because\nCloud Spanner chooses the exact timestamp, this mode works even if\nthe client's local clock is substantially skewed from Cloud Spanner\ncommit timestamps.\n\nUseful for reading the freshest data available at a nearby\nreplica, while bounding the possible staleness if the local\nreplica has fallen behind.\n\nNote that this option can only be used in single-use\ntransactions.", "format" "google-duration", "type" "string"}, "returnReadTimestamp" {"description" "If true, the Cloud Spanner-selected read timestamp is included in\nthe Transaction message that describes the transaction.", "type" "boolean"}, "exactStaleness" {"description" "Executes all reads at a timestamp that is `exact_staleness`\nold. The timestamp is chosen soon after the read is started.\n\nGuarantees that all writes that have committed more than the\nspecified number of seconds ago are visible. Because Cloud Spanner\nchooses the exact timestamp, this mode works even if the client's\nlocal clock is substantially skewed from Cloud Spanner commit\ntimestamps.\n\nUseful for reading at nearby replicas without the distributed\ntimestamp negotiation overhead of `max_staleness`.", "format" "google-duration", "type" "string"}, "strong" {"description" "Read at a timestamp where all previously committed transactions\nare visible.", "type" "boolean"}, "minReadTimestamp" {"description" "Executes all reads at a timestamp >= `min_read_timestamp`.\n\nThis is useful for requesting fresher data than some previous\nread, or data that is fresh enough to observe the effects of some\npreviously committed transaction whose timestamp is known.\n\nNote that this option can only be used in single-use transactions.\n\nA timestamp in RFC3339 UTC \\\"Zulu\\\" format, accurate to nanoseconds.\nExample: `\"2014-10-02T15:01:23.045123456Z\"`.", "format" "google-datetime", "type" "string"}}, "id" "ReadOnly"}, "ResultSetMetadata" {"id" "ResultSetMetadata", "description" "Metadata about a ResultSet or PartialResultSet.", "type" "object", "properties" {"rowType" {"$ref" "StructType", "description" "Indicates the field names and types for the rows in the result\nset.  For example, a SQL query like `\"SELECT UserId, UserName FROM\nUsers\"` could return a `row_type` value like:\n\n    \"fields\": [\n      { \"name\": \"UserId\", \"type\": { \"code\": \"INT64\" } },\n      { \"name\": \"UserName\", \"type\": { \"code\": \"STRING\" } },\n    ]"}, "transaction" {"description" "If the read or SQL query began a transaction as a side-effect, the\ninformation about the new transaction is yielded here.", "$ref" "Transaction"}}}, "UpdateInstanceMetadata" {"description" "Metadata type for the operation returned by\nUpdateInstance.", "type" "object", "properties" {"instance" {"description" "The desired end state of the update.", "$ref" "Instance"}, "startTime" {"description" "The time at which UpdateInstance\nrequest was received.", "format" "google-datetime", "type" "string"}, "cancelTime" {"description" "The time at which this operation was cancelled. If set, this operation is\nin the process of undoing itself (which is guaranteed to succeed) and\ncannot be cancelled again.", "format" "google-datetime", "type" "string"}, "endTime" {"type" "string", "description" "The time at which this operation failed or was completed successfully.", "format" "google-datetime"}}, "id" "UpdateInstanceMetadata"}, "KeyRange" {"type" "object", "properties" {"startClosed" {"description" "If the start is closed, then the range includes all rows whose\nfirst `len(start_closed)` key columns exactly match `start_closed`.", "type" "array", "items" {"type" "any"}}, "startOpen" {"description" "If the start is open, then the range excludes rows whose first\n`len(start_open)` key columns exactly match `start_open`.", "type" "array", "items" {"type" "any"}}, "endOpen" {"type" "array", "items" {"type" "any"}, "description" "If the end is open, then the range excludes rows whose first\n`len(end_open)` key columns exactly match `end_open`."}, "endClosed" {"description" "If the end is closed, then the range includes all rows whose\nfirst `len(end_closed)` key columns exactly match `end_closed`.", "type" "array", "items" {"type" "any"}}}, "id" "KeyRange", "description" "KeyRange represents a range of rows in a table or index.\n\nA range has a start key and an end key. These keys can be open or\nclosed, indicating if the range includes rows with that key.\n\nKeys are represented by lists, where the ith value in the list\ncorresponds to the ith component of the table or index primary key.\nIndividual values are encoded as described\nhere.\n\nFor example, consider the following table definition:\n\n    CREATE TABLE UserEvents (\n      UserName STRING(MAX),\n      EventDate STRING(10)\n    ) PRIMARY KEY(UserName, EventDate);\n\nThe following keys name rows in this table:\n\n    \"Bob\", \"2014-09-23\"\n\nSince the `UserEvents` table's `PRIMARY KEY` clause names two\ncolumns, each `UserEvents` key has two elements; the first is the\n`UserName`, and the second is the `EventDate`.\n\nKey ranges with multiple components are interpreted\nlexicographically by component using the table or index key's declared\nsort order. For example, the following range returns all events for\nuser `\"Bob\"` that occurred in the year 2015:\n\n    \"start_closed\": [\"Bob\", \"2015-01-01\"]\n    \"end_closed\": [\"Bob\", \"2015-12-31\"]\n\nStart and end keys can omit trailing key components. This affects the\ninclusion and exclusion of rows that exactly match the provided key\ncomponents: if the key is closed, then rows that exactly match the\nprovided components are included; if the key is open, then rows\nthat exactly match are not included.\n\nFor example, the following range includes all events for `\"Bob\"` that\noccurred during and after the year 2000:\n\n    \"start_closed\": [\"Bob\", \"2000-01-01\"]\n    \"end_closed\": [\"Bob\"]\n\nThe next example retrieves all events for `\"Bob\"`:\n\n    \"start_closed\": [\"Bob\"]\n    \"end_closed\": [\"Bob\"]\n\nTo retrieve events before the year 2000:\n\n    \"start_closed\": [\"Bob\"]\n    \"end_open\": [\"Bob\", \"2000-01-01\"]\n\nThe following range includes all rows in the table:\n\n    \"start_closed\": []\n    \"end_closed\": []\n\nThis range returns all users whose `UserName` begins with any\ncharacter from A to C:\n\n    \"start_closed\": [\"A\"]\n    \"end_open\": [\"D\"]\n\nThis range returns all users whose `UserName` begins with B:\n\n    \"start_closed\": [\"B\"]\n    \"end_open\": [\"C\"]\n\nKey ranges honor column sort order. For example, suppose a table is\ndefined as follows:\n\n    CREATE TABLE DescendingSortedTable {\n      Key INT64,\n      ...\n    ) PRIMARY KEY(Key DESC);\n\nThe following range retrieves all rows with key values between 1\nand 100 inclusive:\n\n    \"start_closed\": [\"100\"]\n    \"end_closed\": [\"1\"]\n\nNote that 100 is passed as the start, and 1 is passed as the end,\nbecause `Key` is a descending column in the schema."}, "SetIamPolicyRequest" {"description" "Request message for `SetIamPolicy` method.", "type" "object", "properties" {"policy" {"description" "REQUIRED: The complete policy to be applied to the `resource`. The size of\nthe policy is limited to a few 10s of KB. An empty policy is a\nvalid policy but certain Cloud Platform services (such as Projects)\nmight reject them.", "$ref" "Policy"}}, "id" "SetIamPolicyRequest"}, "PartialResultSet" {"id" "PartialResultSet", "description" "Partial results from a streaming read or SQL query. Streaming reads and\nSQL queries better tolerate large result sets, large rows, and large\nvalues, but are a little trickier to consume.", "type" "object", "properties" {"metadata" {"$ref" "ResultSetMetadata", "description" "Metadata about the result set, such as row type information.\nOnly present in the first response."}, "values" {"description" "A streamed result set consists of a stream of values, which might\nbe split into many `PartialResultSet` messages to accommodate\nlarge rows and/or large values. Every N complete values defines a\nrow, where N is equal to the number of entries in\nmetadata.row_type.fields.\n\nMost values are encoded based on type as described\nhere.\n\nIt is possible that the last value in values is \"chunked\",\nmeaning that the rest of the value is sent in subsequent\n`PartialResultSet`(s). This is denoted by the chunked_value\nfield. Two or more chunked values can be merged to form a\ncomplete value as follows:\n\n  * `bool/number/null`: cannot be chunked\n  * `string`: concatenate the strings\n  * `list`: concatenate the lists. If the last element in a list is a\n    `string`, `list`, or `object`, merge it with the first element in\n    the next list by applying these rules recursively.\n  * `object`: concatenate the (field name, field value) pairs. If a\n    field name is duplicated, then apply these rules recursively\n    to merge the field values.\n\nSome examples of merging:\n\n    # Strings are concatenated.\n    \"foo\", \"bar\" => \"foobar\"\n\n    # Lists of non-strings are concatenated.\n    [2, 3], [4] => [2, 3, 4]\n\n    # Lists are concatenated, but the last and first elements are merged\n    # because they are strings.\n    [\"a\", \"b\"], [\"c\", \"d\"] => [\"a\", \"bc\", \"d\"]\n\n    # Lists are concatenated, but the last and first elements are merged\n    # because they are lists. Recursively, the last and first elements\n    # of the inner lists are merged because they are strings.\n    [\"a\", [\"b\", \"c\"]], [[\"d\"], \"e\"] => [\"a\", [\"b\", \"cd\"], \"e\"]\n\n    # Non-overlapping object fields are combined.\n    {\"a\": \"1\"}, {\"b\": \"2\"} => {\"a\": \"1\", \"b\": 2\"}\n\n    # Overlapping object fields are merged.\n    {\"a\": \"1\"}, {\"a\": \"2\"} => {\"a\": \"12\"}\n\n    # Examples of merging objects containing lists of strings.\n    {\"a\": [\"1\"]}, {\"a\": [\"2\"]} => {\"a\": [\"12\"]}\n\nFor a more complete example, suppose a streaming SQL query is\nyielding a result set whose rows contain a single string\nfield. The following `PartialResultSet`s might be yielded:\n\n    {\n      \"metadata\": { ... }\n      \"values\": [\"Hello\", \"W\"]\n      \"chunked_value\": true\n      \"resume_token\": \"Af65...\"\n    }\n    {\n      \"values\": [\"orl\"]\n      \"chunked_value\": true\n      \"resume_token\": \"Bqp2...\"\n    }\n    {\n      \"values\": [\"d\"]\n      \"resume_token\": \"Zx1B...\"\n    }\n\nThis sequence of `PartialResultSet`s encodes two rows, one\ncontaining the field value `\"Hello\"`, and a second containing the\nfield value `\"World\" = \"W\" + \"orl\" + \"d\"`.", "type" "array", "items" {"type" "any"}}, "resumeToken" {"type" "string", "description" "Streaming calls might be interrupted for a variety of reasons, such\nas TCP connection loss. If this occurs, the stream of results can\nbe resumed by re-sending the original request and including\n`resume_token`. Note that executing any other transaction in the\nsame session invalidates the token.", "format" "byte"}, "stats" {"$ref" "ResultSetStats", "description" "Query plan and execution statistics for the statement that produced this\nstreaming result set. These can be requested by setting\nExecuteSqlRequest.query_mode and are sent\nonly once with the last response in the stream.\nThis field will also be present in the last response for DML\nstatements."}, "chunkedValue" {"description" "If true, then the final value in values is chunked, and must\nbe combined with more values from subsequent `PartialResultSet`s\nto obtain a complete field value.", "type" "boolean"}}}, "Partition" {"description" "Information returned for each partition returned in a\nPartitionResponse.", "type" "object", "properties" {"partitionToken" {"description" "This token can be passed to Read, StreamingRead, ExecuteSql, or\nExecuteStreamingSql requests to restrict the results to those identified by\nthis partition token.", "format" "byte", "type" "string"}}, "id" "Partition"}, "CreateDatabaseMetadata" {"description" "Metadata type for the operation returned by\nCreateDatabase.", "type" "object", "properties" {"database" {"description" "The database being created.", "type" "string"}}, "id" "CreateDatabaseMetadata"}, "PartitionOptions" {"description" "Options for a PartitionQueryRequest and\nPartitionReadRequest.", "type" "object", "properties" {"partitionSizeBytes" {"description" "**Note:** This hint is currently ignored by PartitionQuery and\nPartitionRead requests.\n\nThe desired data size for each partition generated.  The default for this\noption is currently 1 GiB.  This is only a hint. The actual size of each\npartition may be smaller or larger than this size request.", "format" "int64", "type" "string"}, "maxPartitions" {"description" "**Note:** This hint is currently ignored by PartitionQuery and\nPartitionRead requests.\n\nThe desired maximum number of partitions to return.  For example, this may\nbe set to the number of workers available.  The default for this option\nis currently 10,000. The maximum value is currently 200,000.  This is only\na hint.  The actual number of partitions returned may be smaller or larger\nthan this maximum count request.", "format" "int64", "type" "string"}}, "id" "PartitionOptions"}, "ReadWrite" {"properties" {}, "id" "ReadWrite", "description" "Message type to initiate a read-write transaction. Currently this\ntransaction type has no options.", "type" "object"}, "UpdateDatabaseDdlRequest" {"description" "Enqueues the given DDL statements to be applied, in order but not\nnecessarily all at once, to the database schema at some point (or\npoints) in the future. The server checks that the statements\nare executable (syntactically valid, name tables that exist, etc.)\nbefore enqueueing them, but they may still fail upon\nlater execution (e.g., if a statement from another batch of\nstatements is applied first and it conflicts in some way, or if\nthere is some data-related problem like a `NULL` value in a column to\nwhich `NOT NULL` would be added). If a statement fails, all\nsubsequent statements in the batch are automatically cancelled.\n\nEach batch of statements is assigned a name which can be used with\nthe Operations API to monitor\nprogress. See the\noperation_id field for more\ndetails.", "type" "object", "properties" {"statements" {"description" "Required. DDL statements to be applied to the database.", "type" "array", "items" {"type" "string"}}, "operationId" {"description" "If empty, the new update request is assigned an\nautomatically-generated operation ID. Otherwise, `operation_id`\nis used to construct the name of the resulting\nOperation.\n\nSpecifying an explicit operation ID simplifies determining\nwhether the statements were executed in the event that the\nUpdateDatabaseDdl call is replayed,\nor the return value is otherwise lost: the database and\n`operation_id` fields can be combined to form the\nname of the resulting\nlongrunning.Operation: `<database>/operations/<operation_id>`.\n\n`operation_id` should be unique within the database, and must be\na valid identifier: `a-z*`. Note that\nautomatically-generated operation IDs always begin with an\nunderscore. If the named operation already exists,\nUpdateDatabaseDdl returns\n`ALREADY_EXISTS`.", "type" "string"}}, "id" "UpdateDatabaseDdlRequest"}, "CreateDatabaseRequest" {"id" "CreateDatabaseRequest", "description" "The request for CreateDatabase.", "type" "object", "properties" {"createStatement" {"description" "Required. A `CREATE DATABASE` statement, which specifies the ID of the\nnew database.  The database ID must conform to the regular expression\n`a-z*[a-z0-9]` and be between 2 and 30 characters in length.\nIf the database ID is a reserved word or if it contains a hyphen, the\ndatabase ID must be enclosed in backticks (`` ` ``).", "type" "string"}, "extraStatements" {"description" "Optional. A list of DDL statements to run inside the newly created\ndatabase. Statements can create tables, indexes, etc. These\nstatements execute atomically with the creation of the database:\nif there is an error in any statement, the database is not created.", "type" "array", "items" {"type" "string"}}}}, "GetDatabaseDdlResponse" {"properties" {"statements" {"description" "A list of formatted DDL statements defining the schema of the database\nspecified in the request.", "type" "array", "items" {"type" "string"}}}, "id" "GetDatabaseDdlResponse", "description" "The response for GetDatabaseDdl.", "type" "object"}, "GetIamPolicyRequest" {"type" "object", "properties" {"options" {"description" "OPTIONAL: A `GetPolicyOptions` object for specifying options to\n`GetIamPolicy`. This field is only used by Cloud IAM.", "$ref" "GetPolicyOptions"}}, "id" "GetIamPolicyRequest", "description" "Request message for `GetIamPolicy` method."}, "RestoreDatabaseRequest" {"description" "The request for\nRestoreDatabase.", "type" "object", "properties" {"databaseId" {"description" "Required. The id of the database to create and restore to. This\ndatabase must not already exist. The `database_id` appended to\n`parent` forms the full database name of the form\n`projects/<project>/instances/<instance>/databases/<database_id>`.", "type" "string"}, "backup" {"description" "Name of the backup from which to restore.  Values are of the form\n`projects/<project>/instances/<instance>/backups/<backup>`.", "type" "string"}}, "id" "RestoreDatabaseRequest"}, "CommitResponse" {"id" "CommitResponse", "description" "The response for Commit.", "type" "object", "properties" {"commitTimestamp" {"type" "string", "description" "The Cloud Spanner timestamp at which the transaction committed.", "format" "google-datetime"}}}, "CreateInstanceRequest" {"description" "The request for CreateInstance.", "type" "object", "properties" {"instanceId" {"description" "Required. The ID of the instance to create.  Valid identifiers are of the\nform `a-z*[a-z0-9]` and must be between 2 and 64 characters in\nlength.", "type" "string"}, "instance" {"description" "Required. The instance to create.  The name may be omitted, but if\nspecified must be `<parent>/instances/<instance_id>`.", "$ref" "Instance"}}, "id" "CreateInstanceRequest"}, "ListDatabaseOperationsResponse" {"type" "object", "properties" {"nextPageToken" {"description" "`next_page_token` can be sent in a subsequent\nListDatabaseOperations\ncall to fetch more of the matching metadata.", "type" "string"}, "operations" {"description" "The list of matching database long-running\noperations. Each operation's name will be\nprefixed by the database's name. The operation's\nmetadata field type\n`metadata.type_url` describes the type of the metadata.", "type" "array", "items" {"$ref" "Operation"}}}, "id" "ListDatabaseOperationsResponse", "description" "The response for\nListDatabaseOperations."}, "ListInstanceConfigsResponse" {"description" "The response for ListInstanceConfigs.", "type" "object", "properties" {"nextPageToken" {"description" "`next_page_token` can be sent in a subsequent\nListInstanceConfigs call to\nfetch more of the matching instance configurations.", "type" "string"}, "instanceConfigs" {"description" "The list of requested instance configurations.", "type" "array", "items" {"$ref" "InstanceConfig"}}}, "id" "ListInstanceConfigsResponse"}, "Policy" {"description" "An Identity and Access Management (IAM) policy, which specifies access\ncontrols for Google Cloud resources.\n\n\nA `Policy` is a collection of `bindings`. A `binding` binds one or more\n`members` to a single `role`. Members can be user accounts, service accounts,\nGoogle groups, and domains (such as G Suite). A `role` is a named list of\npermissions; each `role` can be an IAM predefined role or a user-created\ncustom role.\n\nOptionally, a `binding` can specify a `condition`, which is a logical\nexpression that allows access to a resource only if the expression evaluates\nto `true`. A condition can add constraints based on attributes of the\nrequest, the resource, or both.\n\n**JSON example:**\n\n    {\n      \"bindings\": [\n        {\n          \"role\": \"roles/resourcemanager.organizationAdmin\",\n          \"members\": [\n            \"user:mike@example.com\",\n            \"group:admins@example.com\",\n            \"domain:google.com\",\n            \"serviceAccount:my-project-id@appspot.gserviceaccount.com\"\n          ]\n        },\n        {\n          \"role\": \"roles/resourcemanager.organizationViewer\",\n          \"members\": [\"user:eve@example.com\"],\n          \"condition\": {\n            \"title\": \"expirable access\",\n            \"description\": \"Does not grant access after Sep 2020\",\n            \"expression\": \"request.time < timestamp('2020-10-01T00:00:00.000Z')\",\n          }\n        }\n      ],\n      \"etag\": \"BwWWja0YfJA=\",\n      \"version\": 3\n    }\n\n**YAML example:**\n\n    bindings:\n    - members:\n      - user:mike@example.com\n      - group:admins@example.com\n      - domain:google.com\n      - serviceAccount:my-project-id@appspot.gserviceaccount.com\n      role: roles/resourcemanager.organizationAdmin\n    - members:\n      - user:eve@example.com\n      role: roles/resourcemanager.organizationViewer\n      condition:\n        title: expirable access\n        description: Does not grant access after Sep 2020\n        expression: request.time < timestamp('2020-10-01T00:00:00.000Z')\n    - etag: BwWWja0YfJA=\n    - version: 3\n\nFor a description of IAM and its features, see the\n[IAM documentation](https://cloud.google.com/iam/docs/).", "type" "object", "properties" {"bindings" {"description" "Associates a list of `members` to a `role`. Optionally, may specify a\n`condition` that determines how and when the `bindings` are applied. Each\nof the `bindings` must contain at least one member.", "type" "array", "items" {"$ref" "Binding"}}, "etag" {"description" "`etag` is used for optimistic concurrency control as a way to help\nprevent simultaneous updates of a policy from overwriting each other.\nIt is strongly suggested that systems make use of the `etag` in the\nread-modify-write cycle to perform policy updates in order to avoid race\nconditions: An `etag` is returned in the response to `getIamPolicy`, and\nsystems are expected to put that etag in the request to `setIamPolicy` to\nensure that their change will be applied to the same version of the policy.\n\n**Important:** If you use IAM Conditions, you must include the `etag` field\nwhenever you call `setIamPolicy`. If you omit this field, then IAM allows\nyou to overwrite a version `3` policy with a version `1` policy, and all of\nthe conditions in the version `3` policy are lost.", "format" "byte", "type" "string"}, "version" {"description" "Specifies the format of the policy.\n\nValid values are `0`, `1`, and `3`. Requests that specify an invalid value\nare rejected.\n\nAny operation that affects conditional role bindings must specify version\n`3`. This requirement applies to the following operations:\n\n* Getting a policy that includes a conditional role binding\n* Adding a conditional role binding to a policy\n* Changing a conditional role binding in a policy\n* Removing any role binding, with or without a condition, from a policy\n  that includes conditions\n\n**Important:** If you use IAM Conditions, you must include the `etag` field\nwhenever you call `setIamPolicy`. If you omit this field, then IAM allows\nyou to overwrite a version `3` policy with a version `1` policy, and all of\nthe conditions in the version `3` policy are lost.\n\nIf a policy does not include any conditions, operations on that policy may\nspecify any valid version or leave the field unset.", "format" "int32", "type" "integer"}}, "id" "Policy"}, "CreateSessionRequest" {"type" "object", "properties" {"session" {"description" "The session to create.", "$ref" "Session"}}, "id" "CreateSessionRequest", "description" "The request for CreateSession."}, "Mutation" {"description" "A modification to one or more Cloud Spanner rows.  Mutations can be\napplied to a Cloud Spanner database by sending them in a\nCommit call.", "type" "object", "properties" {"delete" {"$ref" "Delete", "description" "Delete rows from a table. Succeeds whether or not the named\nrows were present."}, "insert" {"$ref" "Write", "description" "Insert new rows in a table. If any of the rows already exist,\nthe write or transaction fails with error `ALREADY_EXISTS`."}, "insertOrUpdate" {"$ref" "Write", "description" "Like insert, except that if the row already exists, then\nits column values are overwritten with the ones provided. Any\ncolumn values not explicitly written are preserved.\n\nWhen using insert_or_update, just as when using insert, all `NOT\nNULL` columns in the table must be given a value. This holds true\neven when the row already exists and will therefore actually be updated."}, "update" {"$ref" "Write", "description" "Update existing rows in a table. If any of the rows does not\nalready exist, the transaction fails with error `NOT_FOUND`."}, "replace" {"description" "Like insert, except that if the row already exists, it is\ndeleted, and the column values provided are inserted\ninstead. Unlike insert_or_update, this means any values not\nexplicitly written become `NULL`.\n\nIn an interleaved table, if you create the child table with the\n`ON DELETE CASCADE` annotation, then replacing a parent row\nalso deletes the child rows. Otherwise, you must delete the\nchild rows before you replace the parent row.", "$ref" "Write"}}, "id" "Mutation"}, "InstanceConfig" {"description" "A possible configuration for a Cloud Spanner instance. Configurations\ndefine the geographic placement of nodes and their replication.", "type" "object", "properties" {"replicas" {"description" "The geographic placement of nodes in this instance configuration and their\nreplication properties.", "type" "array", "items" {"$ref" "ReplicaInfo"}}, "name" {"description" "A unique identifier for the instance configuration.  Values\nare of the form\n`projects/<project>/instanceConfigs/a-z*`", "type" "string"}, "displayName" {"type" "string", "description" "The name of this instance configuration as it appears in UIs."}}, "id" "InstanceConfig"}, "Field" {"description" "Message representing a single field of a struct.", "type" "object", "properties" {"name" {"description" "The name of the field. For reads, this is the column name. For\nSQL queries, it is the column alias (e.g., `\"Word\"` in the\nquery `\"SELECT 'hello' AS Word\"`), or the column name (e.g.,\n`\"ColName\"` in the query `\"SELECT ColName FROM Table\"`). Some\ncolumns might have an empty name (e.g., !\"SELECT\nUPPER(ColName)\"`). Note that a query result can contain\nmultiple fields with the same name.", "type" "string"}, "type" {"$ref" "Type", "description" "The type of the field."}}, "id" "Field"}, "CreateInstanceMetadata" {"description" "Metadata type for the operation returned by\nCreateInstance.", "type" "object", "properties" {"cancelTime" {"description" "The time at which this operation was cancelled. If set, this operation is\nin the process of undoing itself (which is guaranteed to succeed) and\ncannot be cancelled again.", "format" "google-datetime", "type" "string"}, "endTime" {"description" "The time at which this operation failed or was completed successfully.", "format" "google-datetime", "type" "string"}, "instance" {"$ref" "Instance", "description" "The instance being created."}, "startTime" {"type" "string", "description" "The time at which the\nCreateInstance request was\nreceived.", "format" "google-datetime"}}, "id" "CreateInstanceMetadata"}, "Instance" {"description" "An isolated set of Cloud Spanner resources on which databases can be hosted.", "type" "object", "properties" {"nodeCount" {"description" "The number of nodes allocated to this instance. This\nmay be zero in API responses for instances that are not yet in state\n`READY`.\n\nSee [the\ndocumentation](https://cloud.google.com/spanner/docs/instances#node_count)\nfor more information about nodes.", "format" "int32", "type" "integer"}, "labels" {"additionalProperties" {"type" "string"}, "description" "Cloud Labels are a flexible and lightweight mechanism for organizing cloud\nresources into groups that reflect a customer's organizational needs and\ndeployment strategies. Cloud Labels can be used to filter collections of\nresources. They can be used to control how resource metrics are aggregated.\nAnd they can be used as arguments to policy management rules (e.g. route,\nfirewall, load balancing, etc.).\n\n * Label keys must be between 1 and 63 characters long and must conform to\n   the following regular expression: `[a-z]([-a-z0-9]*[a-z0-9])?`.\n * Label values must be between 0 and 63 characters long and must conform\n   to the regular expression `([a-z]([-a-z0-9]*[a-z0-9])?)?`.\n * No more than 64 labels can be associated with a given resource.\n\nSee https://goo.gl/xmQnxf for more information on and examples of labels.\n\nIf you plan to use labels in your own code, please note that additional\ncharacters may be allowed in the future. And so you are advised to use an\ninternal label representation, such as JSON, which doesn't rely upon\nspecific characters being disallowed.  For example, representing labels\nas the string:  name + \"_\" + value  would prove problematic if we were to\nallow \"_\" in a future release.", "type" "object"}, "config" {"description" "Required. The name of the instance's configuration. Values are of the form\n`projects/<project>/instanceConfigs/<configuration>`. See\nalso InstanceConfig and\nListInstanceConfigs.", "type" "string"}, "state" {"type" "string", "enumDescriptions" ["Not specified." "The instance is still being created. Resources may not be\navailable yet, and operations such as database creation may not\nwork." "The instance is fully created and ready to do work such as\ncreating databases."], "enum" ["STATE_UNSPECIFIED" "CREATING" "READY"], "description" "Output only. The current instance state. For\nCreateInstance, the state must be\neither omitted or set to `CREATING`. For\nUpdateInstance, the state must be\neither omitted or set to `READY`."}, "name" {"description" "Required. A unique identifier for the instance, which cannot be changed\nafter the instance is created. Values are of the form\n`projects/<project>/instances/a-z*[a-z0-9]`. The final\nsegment of the name must be between 2 and 64 characters in length.", "type" "string"}, "displayName" {"description" "Required. The descriptive name for this instance as it appears in UIs.\nMust be unique per project and between 4 and 30 characters in length.", "type" "string"}, "endpointUris" {"description" "Deprecated. This field is not populated.", "type" "array", "items" {"type" "string"}}}, "id" "Instance"}, "Transaction" {"type" "object", "properties" {"readTimestamp" {"description" "For snapshot read-only transactions, the read timestamp chosen\nfor the transaction. Not returned by default: see\nTransactionOptions.ReadOnly.return_read_timestamp.\n\nA timestamp in RFC3339 UTC \\\"Zulu\\\" format, accurate to nanoseconds.\nExample: `\"2014-10-02T15:01:23.045123456Z\"`.", "format" "google-datetime", "type" "string"}, "id" {"description" "`id` may be used to identify the transaction in subsequent\nRead,\nExecuteSql,\nCommit, or\nRollback calls.\n\nSingle-use read-only transactions do not have IDs, because\nsingle-use transactions do not support multiple requests.", "format" "byte", "type" "string"}}, "id" "Transaction", "description" "A transaction."}, "Session" {"description" "A session in the Cloud Spanner API.", "type" "object", "properties" {"labels" {"additionalProperties" {"type" "string"}, "description" "The labels for the session.\n\n * Label keys must be between 1 and 63 characters long and must conform to\n   the following regular expression: `[a-z]([-a-z0-9]*[a-z0-9])?`.\n * Label values must be between 0 and 63 characters long and must conform\n   to the regular expression `([a-z]([-a-z0-9]*[a-z0-9])?)?`.\n * No more than 64 labels can be associated with a given session.\n\nSee https://goo.gl/xmQnxf for more information on and examples of labels.", "type" "object"}, "createTime" {"description" "Output only. The timestamp when the session is created.", "format" "google-datetime", "type" "string"}, "name" {"description" "The name of the session. This is always system-assigned; values provided\nwhen creating a session are ignored.", "type" "string"}, "approximateLastUseTime" {"description" "Output only. The approximate timestamp when the session is last used. It is\ntypically earlier than the actual last use time.", "format" "google-datetime", "type" "string"}}, "id" "Session"}, "KeySet" {"id" "KeySet", "description" "`KeySet` defines a collection of Cloud Spanner keys and/or key ranges. All\nthe keys are expected to be in the same table or index. The keys need\nnot be sorted in any particular way.\n\nIf the same key is specified multiple times in the set (for example\nif two ranges, two keys, or a key and a range overlap), Cloud Spanner\nbehaves as if the key were only specified once.", "type" "object", "properties" {"ranges" {"description" "A list of key ranges. See KeyRange for more information about\nkey range specifications.", "type" "array", "items" {"$ref" "KeyRange"}}, "keys" {"description" "A list of specific keys. Entries in `keys` should have exactly as\nmany elements as there are columns in the primary or index key\nwith which this `KeySet` is used.  Individual key values are\nencoded as described here.", "type" "array", "items" {"type" "array", "items" {"type" "any"}}}, "all" {"description" "For convenience `all` can be set to `true` to indicate that this\n`KeySet` matches all keys in the table or index. Note that any keys\nspecified in `keys` or `ranges` are only yielded once.", "type" "boolean"}}}, "PartitionReadRequest" {"description" "The request for PartitionRead", "type" "object", "properties" {"columns" {"description" "The columns of table to be returned for each row matching\nthis request.", "type" "array", "items" {"type" "string"}}, "transaction" {"$ref" "TransactionSelector", "description" "Read only snapshot transactions are supported, read/write and single use\ntransactions are not."}, "table" {"description" "Required. The name of the table in the database to be read.", "type" "string"}, "partitionOptions" {"$ref" "PartitionOptions", "description" "Additional options that affect how many partitions are created."}, "index" {"description" "If non-empty, the name of an index on table. This index is\nused instead of the table primary key when interpreting key_set\nand sorting result rows. See key_set for further information.", "type" "string"}, "keySet" {"description" "Required. `key_set` identifies the rows to be yielded. `key_set` names the\nprimary keys of the rows in table to be yielded, unless index\nis present. If index is present, then key_set instead names\nindex keys in index.\n\nIt is not an error for the `key_set` to name rows that do not\nexist in the database. Read yields nothing for nonexistent rows.", "$ref" "KeySet"}}, "id" "PartitionReadRequest"}, "Database" {"id" "Database", "description" "A Cloud Spanner database.", "type" "object", "properties" {"restoreInfo" {"$ref" "RestoreInfo", "description" "Output only. Applicable only for restored databases. Contains information\nabout the restore source."}, "createTime" {"description" "Output only. If exists, the time at which the database creation started.", "format" "google-datetime", "type" "string"}, "state" {"enum" ["STATE_UNSPECIFIED" "CREATING" "READY" "READY_OPTIMIZING"], "description" "Output only. The current database state.", "type" "string", "enumDescriptions" ["Not specified." "The database is still being created. Operations on the database may fail\nwith `FAILED_PRECONDITION` in this state." "The database is fully created and ready for use." "The database is fully created and ready for use, but is still\nbeing optimized for performance and cannot handle full load.\n\nIn this state, the database still references the backup\nit was restore from, preventing the backup\nfrom being deleted. When optimizations are complete, the full performance\nof the database will be restored, and the database will transition to\n`READY` state."]}, "name" {"description" "Required. The name of the database. Values are of the form\n`projects/<project>/instances/<instance>/databases/<database>`,\nwhere `<database>` is as specified in the `CREATE DATABASE`\nstatement. This name can be passed to other API methods to\nidentify the database.", "type" "string"}}}, "PartitionedDml" {"id" "PartitionedDml", "description" "Message type to initiate a Partitioned DML transaction.", "type" "object", "properties" {}}, "ListDatabasesResponse" {"description" "The response for ListDatabases.", "type" "object", "properties" {"nextPageToken" {"description" "`next_page_token` can be sent in a subsequent\nListDatabases call to fetch more\nof the matching databases.", "type" "string"}, "databases" {"type" "array", "items" {"$ref" "Database"}, "description" "Databases that matched the request."}}, "id" "ListDatabasesResponse"}}}