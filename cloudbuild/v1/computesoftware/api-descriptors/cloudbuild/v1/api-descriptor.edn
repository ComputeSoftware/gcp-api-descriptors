#:compute.gcp.descriptor{:name "cloudbuild", :title "Cloud Build API", :api-version "v1", :revision "20200410", :endpoint #:compute.gcp.descriptor{:url "https://cloudbuild.googleapis.com/", :batch-path "batch", :service-path ""}, :parameters {"callback" {"location" "query", "description" "JSONP", "type" "string"}, "uploadType" {"description" "Legacy upload protocol for media (e.g. \"media\", \"multipart\").", "type" "string", "location" "query"}, "key" {"type" "string", "location" "query", "description" "API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token."}, "access_token" {"location" "query", "description" "OAuth access token.", "type" "string"}, "oauth_token" {"location" "query", "description" "OAuth 2.0 token for the current user.", "type" "string"}, "prettyPrint" {"description" "Returns response with indentations and line breaks.", "type" "boolean", "default" "true", "location" "query"}, "alt" {"enum" ["json" "media" "proto"], "type" "string", "enumDescriptions" ["Responses with Content-Type of application/json" "Media download with context-dependent Content-Type" "Responses with Content-Type of application/x-protobuf"], "location" "query", "description" "Data format for response.", "default" "json"}, "$.xgafv" {"description" "V1 error format.", "type" "string", "enumDescriptions" ["v1 error format" "v2 error format"], "location" "query", "enum" ["1" "2"]}, "fields" {"location" "query", "description" "Selector specifying which fields to include in a partial response.", "type" "string"}, "upload_protocol" {"type" "string", "location" "query", "description" "Upload protocol for media (e.g. \"raw\", \"multipart\")."}, "quotaUser" {"type" "string", "location" "query", "description" "Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters."}}, :op->info {"cloudbuild.projects.triggers.get" #:compute.gcp.descriptor{:http-method :get, :path "v1/projects/{projectId}/triggers/{triggerId}", :response {"$ref" "BuildTrigger"}, :parameters {"triggerId" {"location" "path", "description" "Required. Identifier (`id` or `name`) of the `BuildTrigger` to get.", "required" true, "type" "string"}, "projectId" {"location" "path", "description" "Required. ID of the project that owns the trigger.", "required" true, "type" "string"}}, :description "Returns information about a `BuildTrigger`.\n\nThis API is experimental."}, "cloudbuild.projects.triggers.patch" #:compute.gcp.descriptor{:http-method :patch, :path "v1/projects/{projectId}/triggers/{triggerId}", :request {"$ref" "BuildTrigger"}, :response {"$ref" "BuildTrigger"}, :parameters {"triggerId" {"required" true, "type" "string", "location" "path", "description" "Required. ID of the `BuildTrigger` to update."}, "projectId" {"location" "path", "description" "Required. ID of the project that owns the trigger.", "required" true, "type" "string"}}, :description "Updates a `BuildTrigger` by its project ID and trigger ID.\n\nThis API is experimental."}, "cloudbuild.projects.builds.retry" #:compute.gcp.descriptor{:http-method :post, :path "v1/projects/{projectId}/builds/{id}:retry", :request {"$ref" "RetryBuildRequest"}, :response {"$ref" "Operation"}, :parameters {"projectId" {"location" "path", "description" "Required. ID of the project.", "required" true, "type" "string"}, "id" {"location" "path", "description" "Required. Build ID of the original build.", "required" true, "type" "string"}}, :description "Creates a new build based on the specified build.\n\nThis method creates a new build using the original build request, which may\nor may not result in an identical build.\n\nFor triggered builds:\n\n* Triggered builds resolve to a precise revision; therefore a retry of a\ntriggered build will result in a build that uses the same revision.\n\nFor non-triggered builds that specify `RepoSource`:\n\n* If the original build built from the tip of a branch, the retried build\nwill build from the tip of that branch, which may not be the same revision\nas the original build.\n* If the original build specified a commit sha or revision ID, the retried\nbuild will use the identical source.\n\nFor builds that specify `StorageSource`:\n\n* If the original build pulled source from Google Cloud Storage without\nspecifying the generation of the object, the new build will use the current\nobject, which may be different from the original build source.\n* If the original build pulled source from Cloud Storage and specified the\ngeneration of the object, the new build will attempt to use the same\nobject, which may or may not be available depending on the bucket's\nlifecycle management settings."}, "cloudbuild.operations.list" #:compute.gcp.descriptor{:http-method :get, :path "v1/operations", :response {"$ref" "ListOperationsResponse"}, :parameters {"name" {"required" true, "type" "string", "pattern" "^operations$", "location" "path", "description" "The name of the operation's parent resource."}, "pageToken" {"location" "query", "description" "The standard list page token.", "type" "string"}, "pageSize" {"description" "The standard list page size.", "format" "int32", "type" "integer", "location" "query"}, "filter" {"location" "query", "description" "The standard list filter.", "type" "string"}}, :description "Lists operations that match the specified filter in the request. If the\nserver doesn't support this method, it returns `UNIMPLEMENTED`.\n\nNOTE: the `name` binding allows API services to override the binding\nto use different resource name schemes, such as `users/*/operations`. To\noverride the binding, API services can add a binding such as\n`\"/v1/{name=users/*}/operations\"` to their service configuration.\nFor backwards compatibility, the default name includes the operations\ncollection id, however overriding users must ensure the name binding\nis the parent resource, without the operations collection id."}, "cloudbuild.projects.triggers.create" #:compute.gcp.descriptor{:http-method :post, :path "v1/projects/{projectId}/triggers", :request {"$ref" "BuildTrigger"}, :response {"$ref" "BuildTrigger"}, :parameters {"projectId" {"required" true, "type" "string", "location" "path", "description" "Required. ID of the project for which to configure automatic builds."}}, :description "Creates a new `BuildTrigger`.\n\nThis API is experimental."}, "cloudbuild.projects.triggers.list" #:compute.gcp.descriptor{:http-method :get, :path "v1/projects/{projectId}/triggers", :response {"$ref" "ListBuildTriggersResponse"}, :parameters {"pageToken" {"description" "Token to provide to skip to a particular spot in the list.", "type" "string", "location" "query"}, "pageSize" {"type" "integer", "location" "query", "description" "Number of results to return in the list.", "format" "int32"}, "projectId" {"location" "path", "description" "Required. ID of the project for which to list BuildTriggers.", "required" true, "type" "string"}}, :description "Lists existing `BuildTrigger`s.\n\nThis API is experimental."}, "cloudbuild.projects.builds.create" #:compute.gcp.descriptor{:http-method :post, :path "v1/projects/{projectId}/builds", :request {"$ref" "Build"}, :response {"$ref" "Operation"}, :parameters {"projectId" {"location" "path", "description" "Required. ID of the project.", "required" true, "type" "string"}}, :description "Starts a build with the specified configuration.\n\nThis method returns a long-running `Operation`, which includes the build\nID. Pass the build ID to `GetBuild` to determine the build status (such as\n`SUCCESS` or `FAILURE`)."}, "cloudbuild.projects.builds.list" #:compute.gcp.descriptor{:http-method :get, :path "v1/projects/{projectId}/builds", :response {"$ref" "ListBuildsResponse"}, :parameters {"projectId" {"location" "path", "description" "Required. ID of the project.", "required" true, "type" "string"}, "filter" {"location" "query", "description" "The raw filter text to constrain the results.", "type" "string"}, "pageToken" {"location" "query", "description" "Token to provide to skip to a particular spot in the list.", "type" "string"}, "pageSize" {"location" "query", "description" "Number of results to return in the list.", "format" "int32", "type" "integer"}}, :description "Lists previously requested builds.\n\nPreviously requested builds may still be in-progress, or may have finished\nsuccessfully or unsuccessfully."}, "cloudbuild.projects.triggers.delete" #:compute.gcp.descriptor{:http-method :delete, :path "v1/projects/{projectId}/triggers/{triggerId}", :response {"$ref" "Empty"}, :parameters {"triggerId" {"location" "path", "description" "Required. ID of the `BuildTrigger` to delete.", "required" true, "type" "string"}, "projectId" {"location" "path", "description" "Required. ID of the project that owns the trigger.", "required" true, "type" "string"}}, :description "Deletes a `BuildTrigger` by its project ID and trigger ID.\n\nThis API is experimental."}, "cloudbuild.operations.get" #:compute.gcp.descriptor{:http-method :get, :path "v1/operations/{operationsId}", :response {"$ref" "Operation"}, :parameters {"name" {"description" "The name of the operation resource.", "required" true, "type" "string", "pattern" "^operations/.*$", "location" "path"}}, :description "Gets the latest state of a long-running operation.  Clients can use this\nmethod to poll the operation result at intervals as recommended by the API\nservice."}, "cloudbuild.projects.triggers.run" #:compute.gcp.descriptor{:http-method :post, :path "v1/projects/{projectId}/triggers/{triggerId}:run", :request {"$ref" "RepoSource"}, :response {"$ref" "Operation"}, :parameters {"triggerId" {"description" "Required. ID of the trigger.", "required" true, "type" "string", "location" "path"}, "projectId" {"required" true, "type" "string", "location" "path", "description" "Required. ID of the project."}}, :description "Runs a `BuildTrigger` at a particular source revision."}, "cloudbuild.projects.builds.cancel" #:compute.gcp.descriptor{:http-method :post, :path "v1/projects/{projectId}/builds/{id}:cancel", :request {"$ref" "CancelBuildRequest"}, :response {"$ref" "Build"}, :parameters {"id" {"required" true, "type" "string", "location" "path", "description" "Required. ID of the build."}, "projectId" {"description" "Required. ID of the project.", "required" true, "type" "string", "location" "path"}}, :description "Cancels a build in progress."}, "cloudbuild.operations.cancel" #:compute.gcp.descriptor{:http-method :post, :path "v1/operations/{operationsId}:cancel", :request {"$ref" "CancelOperationRequest"}, :response {"$ref" "Empty"}, :parameters {"name" {"required" true, "type" "string", "pattern" "^operations/.*$", "location" "path", "description" "The name of the operation resource to be cancelled."}}, :description "Starts asynchronous cancellation on a long-running operation.  The server\nmakes a best effort to cancel the operation, but success is not\nguaranteed.  If the server doesn't support this method, it returns\n`google.rpc.Code.UNIMPLEMENTED`.  Clients can use\nOperations.GetOperation or\nother methods to check whether the cancellation succeeded or whether the\noperation completed despite cancellation. On successful cancellation,\nthe operation is not deleted; instead, it becomes an operation with\nan Operation.error value with a google.rpc.Status.code of 1,\ncorresponding to `Code.CANCELLED`."}, "cloudbuild.projects.builds.get" #:compute.gcp.descriptor{:http-method :get, :path "v1/projects/{projectId}/builds/{id}", :response {"$ref" "Build"}, :parameters {"projectId" {"location" "path", "description" "Required. ID of the project.", "required" true, "type" "string"}, "id" {"required" true, "type" "string", "location" "path", "description" "Required. ID of the build."}}, :description "Returns information about a previously requested build.\n\nThe `Build` that is returned includes its status (such as `SUCCESS`,\n`FAILURE`, or `WORKING`), and timing information."}}, :schemas {"GitHubEventsConfig" {"type" "object", "properties" {"pullRequest" {"$ref" "PullRequestFilter", "description" "filter to match changes in pull requests."}, "push" {"$ref" "PushFilter", "description" "filter to match changes in refs like branches, tags."}, "installationId" {"description" "The installationID that emits the GitHub event.", "format" "int64", "type" "string"}, "owner" {"type" "string", "description" "Owner of the repository. For example: The owner for\nhttps://github.com/googlecloudplatform/cloud-builders is\n\"googlecloudplatform\"."}, "name" {"description" "Name of the repository. For example: The name for\nhttps://github.com/googlecloudplatform/cloud-builders is \"cloud-builders\".", "type" "string"}}, "id" "GitHubEventsConfig", "description" "GitHubEventsConfig describes the configuration of a trigger that creates a\nbuild whenever a GitHub event is received.\n\nThis message is experimental."}, "ListBuildTriggersResponse" {"description" "Response containing existing `BuildTriggers`.", "type" "object", "properties" {"nextPageToken" {"type" "string", "description" "Token to receive the next page of results."}, "triggers" {"description" "`BuildTriggers` for the project, sorted by `create_time` descending.", "type" "array", "items" {"$ref" "BuildTrigger"}}}, "id" "ListBuildTriggersResponse"}, "Empty" {"description" "A generic empty message that you can re-use to avoid defining duplicated\nempty messages in your APIs. A typical example is to use it as the request\nor the response type of an API method. For instance:\n\n    service Foo {\n      rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty);\n    }\n\nThe JSON representation for `Empty` is empty JSON object `{}`.", "type" "object", "properties" {}, "id" "Empty"}, "RepoSource" {"description" "Location of the source in a Google Cloud Source Repository.", "type" "object", "properties" {"commitSha" {"description" "Explicit commit SHA to build.", "type" "string"}, "invertRegex" {"description" "Only trigger a build if the revision regex does NOT match the revision\nregex.", "type" "boolean"}, "substitutions" {"additionalProperties" {"type" "string"}, "description" "Substitutions to use in a triggered build.\nShould only be used with RunBuildTrigger", "type" "object"}, "branchName" {"description" "Regex matching branches to build.\n\nThe syntax of the regular expressions accepted is the syntax accepted by\nRE2 and described at https://github.com/google/re2/wiki/Syntax", "type" "string"}, "dir" {"description" "Directory, relative to the source root, in which to run the build.\n\nThis must be a relative path. If a step's `dir` is specified and is an\nabsolute path, this value is ignored for that step's execution.", "type" "string"}, "tagName" {"type" "string", "description" "Regex matching tags to build.\n\nThe syntax of the regular expressions accepted is the syntax accepted by\nRE2 and described at https://github.com/google/re2/wiki/Syntax"}, "projectId" {"description" "ID of the project that owns the Cloud Source Repository. If omitted, the\nproject ID requesting the build is assumed.", "type" "string"}, "repoName" {"description" "Required. Name of the Cloud Source Repository.", "type" "string"}}, "id" "RepoSource"}, "Secret" {"description" "Pairs a set of secret environment variables containing encrypted\nvalues with the Cloud KMS key to use to decrypt the value.", "type" "object", "properties" {"kmsKeyName" {"description" "Cloud KMS key name to use to decrypt these envs.", "type" "string"}, "secretEnv" {"additionalProperties" {"format" "byte", "type" "string"}, "description" "Map of environment variable name to its encrypted value.\n\nSecret environment variables must be unique across all of a build's\nsecrets, and must be used by at least one build step. Values can be at most\n64 KB in size. There can be at most 100 secret values across all of a\nbuild's secrets.", "type" "object"}}, "id" "Secret"}, "ListOperationsResponse" {"id" "ListOperationsResponse", "description" "The response message for Operations.ListOperations.", "type" "object", "properties" {"nextPageToken" {"description" "The standard List next-page token.", "type" "string"}, "operations" {"description" "A list of operations that matches the specified filter in the request.", "type" "array", "items" {"$ref" "Operation"}}}}, "Volume" {"description" "Volume describes a Docker container volume which is mounted into build steps\nin order to persist files across build step execution.", "type" "object", "properties" {"path" {"type" "string", "description" "Path at which to mount the volume.\n\nPaths must be absolute and cannot conflict with other volume paths on the\nsame build step or with certain reserved volume paths."}, "name" {"description" "Name of the volume to mount.\n\nVolume names must be unique per build step and must be valid names for\nDocker volumes. Each named volume must be used by at least two build steps.", "type" "string"}}, "id" "Volume"}, "Source" {"id" "Source", "description" "Location of the source in a supported storage service.", "type" "object", "properties" {"storageSource" {"$ref" "StorageSource", "description" "If provided, get the source from this location in Google Cloud Storage."}, "repoSource" {"$ref" "RepoSource", "description" "If provided, get the source from this location in a Cloud Source\nRepository."}}}, "RetryBuildRequest" {"type" "object", "properties" {}, "id" "RetryBuildRequest", "description" "Specifies a build to retry."}, "SourceProvenance" {"description" "Provenance of the source. Ways to find the original source, or verify that\nsome source was used for this build.", "type" "object", "properties" {"fileHashes" {"type" "object", "additionalProperties" {"$ref" "FileHashes"}, "description" "Output only. Hash(es) of the build source, which can be used to verify that\nthe original source integrity was maintained in the build. Note that\n`FileHashes` will only be populated if `BuildOptions` has requested a\n`SourceProvenanceHash`.\n\nThe keys to this map are file paths used as build source and the values\ncontain the hash values for those files.\n\nIf the build source came in a single package such as a gzipped tarfile\n(`.tar.gz`), the `FileHash` will be for the single path to that file."}, "resolvedRepoSource" {"$ref" "RepoSource", "description" "A copy of the build's `source.repo_source`, if exists, with any\nrevisions resolved."}, "resolvedStorageSource" {"$ref" "StorageSource", "description" "A copy of the build's `source.storage_source`, if exists, with any\ngenerations resolved."}}, "id" "SourceProvenance"}, "FileHashes" {"id" "FileHashes", "description" "Container message for hashes of byte content of files, used in\nSourceProvenance messages to verify integrity of source input to the build.", "type" "object", "properties" {"fileHash" {"description" "Collection of file hashes.", "type" "array", "items" {"$ref" "Hash"}}}}, "Hash" {"id" "Hash", "description" "Container message for hash values.", "type" "object", "properties" {"value" {"type" "string", "description" "The hash value.", "format" "byte"}, "type" {"description" "The type of hash that was performed.", "type" "string", "enumDescriptions" ["No hash requested." "Use a sha256 hash." "Use a md5 hash."], "enum" ["NONE" "SHA256" "MD5"]}}}, "TimeSpan" {"description" "Start and end times for a build execution phase.", "type" "object", "properties" {"startTime" {"description" "Start of time span.", "format" "google-datetime", "type" "string"}, "endTime" {"description" "End of time span.", "format" "google-datetime", "type" "string"}}, "id" "TimeSpan"}, "Operation" {"id" "Operation", "description" "This resource represents a long-running operation that is the result of a\nnetwork API call.", "type" "object", "properties" {"done" {"description" "If the value is `false`, it means the operation is still in progress.\nIf `true`, the operation is completed, and either `error` or `response` is\navailable.", "type" "boolean"}, "response" {"description" "The normal response of the operation in case of success.  If the original\nmethod returns no data on success, such as `Delete`, the response is\n`google.protobuf.Empty`.  If the original method is standard\n`Get`/`Create`/`Update`, the response should be the resource.  For other\nmethods, the response should have the type `XxxResponse`, where `Xxx`\nis the original method name.  For example, if the original method name\nis `TakeSnapshot()`, the inferred response type is\n`TakeSnapshotResponse`.", "type" "object", "additionalProperties" {"type" "any", "description" "Properties of the object. Contains field @type with type URL."}}, "name" {"description" "The server-assigned name, which is only unique within the same service that\noriginally returns it. If you use the default HTTP mapping, the\n`name` should be a resource name ending with `operations/{unique_id}`.", "type" "string"}, "error" {"$ref" "Status", "description" "The error result of the operation in case of failure or cancellation."}, "metadata" {"type" "object", "additionalProperties" {"type" "any", "description" "Properties of the object. Contains field @type with type URL."}, "description" "Service-specific metadata associated with the operation.  It typically\ncontains progress information and common metadata such as create time.\nSome services might not provide such metadata.  Any method that returns a\nlong-running operation should document the metadata type, if any."}}}, "Status" {"description" "The `Status` type defines a logical error model that is suitable for\ndifferent programming environments, including REST APIs and RPC APIs. It is\nused by [gRPC](https://github.com/grpc). Each `Status` message contains\nthree pieces of data: error code, error message, and error details.\n\nYou can find out more about this error model and how to work with it in the\n[API Design Guide](https://cloud.google.com/apis/design/errors).", "type" "object", "properties" {"message" {"description" "A developer-facing error message, which should be in English. Any\nuser-facing error message should be localized and sent in the\ngoogle.rpc.Status.details field, or localized by the client.", "type" "string"}, "details" {"description" "A list of messages that carry the error details.  There is a common set of\nmessage types for APIs to use.", "type" "array", "items" {"additionalProperties" {"description" "Properties of the object. Contains field @type with type URL.", "type" "any"}, "type" "object"}}, "code" {"description" "The status code, which should be an enum value of google.rpc.Code.", "format" "int32", "type" "integer"}}, "id" "Status"}, "Artifacts" {"description" "Artifacts produced by a build that should be uploaded upon\nsuccessful completion of all build steps.", "type" "object", "properties" {"images" {"description" "A list of images to be pushed upon the successful completion of all build\nsteps.\n\nThe images will be pushed using the builder service account's credentials.\n\nThe digests of the pushed images will be stored in the Build resource's\nresults field.\n\nIf any of the images fail to be pushed, the build is marked FAILURE.", "type" "array", "items" {"type" "string"}}, "objects" {"description" "A list of objects to be uploaded to Cloud Storage upon successful\ncompletion of all build steps.\n\nFiles in the workspace matching specified paths globs will be uploaded to\nthe specified Cloud Storage location using the builder service account's\ncredentials.\n\nThe location and generation of the uploaded objects will be stored in the\nBuild resource's results field.\n\nIf any objects fail to be pushed, the build is marked FAILURE.", "$ref" "ArtifactObjects"}}, "id" "Artifacts"}, "PushFilter" {"type" "object", "properties" {"branch" {"description" "Regexes matching branches to build.\n\nThe syntax of the regular expressions accepted is the syntax accepted by\nRE2 and described at https://github.com/google/re2/wiki/Syntax", "type" "string"}, "invertRegex" {"type" "boolean", "description" "When true, only trigger a build if the revision regex does NOT match the\ngit_ref regex."}, "tag" {"type" "string", "description" "Regexes matching tags to build.\n\nThe syntax of the regular expressions accepted is the syntax accepted by\nRE2 and described at https://github.com/google/re2/wiki/Syntax"}}, "id" "PushFilter", "description" "Push contains filter properties for matching GitHub git pushes."}, "ArtifactResult" {"type" "object", "properties" {"location" {"description" "The path of an artifact in a Google Cloud Storage bucket, with the\ngeneration number. For example,\n`gs://mybucket/path/to/output.jar#generation`.", "type" "string"}, "fileHash" {"description" "The file hash of the artifact.", "type" "array", "items" {"$ref" "FileHashes"}}}, "id" "ArtifactResult", "description" "An artifact that was uploaded during a build. This\nis a single record in the artifact manifest JSON file."}, "BuildStep" {"description" "A step in the build pipeline.", "type" "object", "properties" {"args" {"description" "A list of arguments that will be presented to the step when it is started.\n\nIf the image used to run the step's container has an entrypoint, the `args`\nare used as arguments to that entrypoint. If the image does not define\nan entrypoint, the first element in args is used as the entrypoint,\nand the remainder will be used as arguments.", "type" "array", "items" {"type" "string"}}, "volumes" {"description" "List of volumes to mount into the build step.\n\nEach volume is created as an empty volume prior to execution of the\nbuild step. Upon completion of the build, volumes and their contents are\ndiscarded.\n\nUsing a named volume in only one step is not valid as it is indicative\nof a build request with an incorrect configuration.", "type" "array", "items" {"$ref" "Volume"}}, "id" {"description" "Unique identifier for this build step, used in `wait_for` to\nreference this build step as a dependency.", "type" "string"}, "name" {"description" "Required. The name of the container image that will run this particular\nbuild step.\n\nIf the image is available in the host's Docker daemon's cache, it\nwill be run directly. If not, the host will attempt to pull the image\nfirst, using the builder service account's credentials if necessary.\n\nThe Docker daemon's cache will already have the latest versions of all of\nthe officially supported build steps\n([https://github.com/GoogleCloudPlatform/cloud-builders](https://github.com/GoogleCloudPlatform/cloud-builders)).\nThe Docker daemon will also have cached many of the layers for some popular\nimages, like \"ubuntu\", \"debian\", but they will be refreshed at the time you\nattempt to use them.\n\nIf you built an image in a previous build step, it will be stored in the\nhost's Docker daemon's cache and is available to use as the name for a\nlater build step.", "type" "string"}, "status" {"type" "string", "enumDescriptions" ["Status of the build is unknown." "Build or step is queued; work has not yet begun." "Build or step is being executed." "Build or step finished successfully." "Build or step failed to complete successfully." "Build or step failed due to an internal cause." "Build or step took longer than was allowed." "Build or step was canceled by a user." "Build was enqueued for longer than the value of `queue_ttl`."], "enum" ["STATUS_UNKNOWN" "QUEUED" "WORKING" "SUCCESS" "FAILURE" "INTERNAL_ERROR" "TIMEOUT" "CANCELLED" "EXPIRED"], "description" "Output only. Status of the build step. At this time, build step status is\nonly updated on build completion; step status is not updated in real-time\nas the build progresses."}, "timeout" {"description" "Time limit for executing this build step. If not defined, the step has no\ntime limit and will be allowed to continue to run until either it completes\nor the build itself times out.", "format" "google-duration", "type" "string"}, "dir" {"description" "Working directory to use when running this step's container.\n\nIf this value is a relative path, it is relative to the build's working\ndirectory. If this value is absolute, it may be outside the build's working\ndirectory, in which case the contents of the path may not be persisted\nacross build step executions, unless a `volume` for that path is specified.\n\nIf the build specifies a `RepoSource` with `dir` and a step with a `dir`,\nwhich specifies an absolute path, the `RepoSource` `dir` is ignored for\nthe step's execution.", "type" "string"}, "pullTiming" {"$ref" "TimeSpan", "description" "Output only. Stores timing information for pulling this build step's\nbuilder image only."}, "env" {"type" "array", "items" {"type" "string"}, "description" "A list of environment variable definitions to be used when running a step.\n\nThe elements are of the form \"KEY=VALUE\" for the environment variable \"KEY\"\nbeing given the value \"VALUE\"."}, "entrypoint" {"type" "string", "description" "Entrypoint to be used instead of the build step image's default entrypoint.\nIf unset, the image's default entrypoint is used."}, "secretEnv" {"description" "A list of environment variables which are encrypted using a Cloud Key\nManagement Service crypto key. These values must be specified in the\nbuild's `Secret`.", "type" "array", "items" {"type" "string"}}, "waitFor" {"description" "The ID(s) of the step(s) that this build step depends on.\nThis build step will not start until all the build steps in `wait_for`\nhave completed successfully. If `wait_for` is empty, this build step will\nstart when all previous build steps in the `Build.Steps` list have\ncompleted successfully.", "type" "array", "items" {"type" "string"}}, "timing" {"description" "Output only. Stores timing information for executing this build step.", "$ref" "TimeSpan"}}, "id" "BuildStep"}, "Build" {"id" "Build", "description" "A build resource in the Cloud Build API.\n\nAt a high level, a `Build` describes where to find source code, how to build\nit (for example, the builder image to run on the source), and where to store\nthe built artifacts.\n\nFields can include the following variables, which will be expanded when the\nbuild is created:\n\n- $PROJECT_ID: the project ID of the build.\n- $BUILD_ID: the autogenerated ID of the build.\n- $REPO_NAME: the source repository name specified by RepoSource.\n- $BRANCH_NAME: the branch name specified by RepoSource.\n- $TAG_NAME: the tag name specified by RepoSource.\n- $REVISION_ID or $COMMIT_SHA: the commit SHA specified by RepoSource or\n  resolved from the specified branch or tag.\n- $SHORT_SHA: first 7 characters of $REVISION_ID or $COMMIT_SHA.", "type" "object", "properties" {"sourceProvenance" {"$ref" "SourceProvenance", "description" "Output only. A permanent fixed identifier for source."}, "steps" {"description" "Required. The operations to be performed on the workspace.", "type" "array", "items" {"$ref" "BuildStep"}}, "finishTime" {"type" "string", "description" "Output only. Time at which execution of the build was finished.\n\nThe difference between finish_time and start_time is the duration of the\nbuild's execution.", "format" "google-datetime"}, "artifacts" {"$ref" "Artifacts", "description" "Artifacts produced by the build that should be uploaded upon\nsuccessful completion of all build steps."}, "tags" {"description" "Tags for annotation of a `Build`. These are not docker tags.", "type" "array", "items" {"type" "string"}}, "queueTtl" {"description" "TTL in queue for this build. If provided and the build is enqueued longer\nthan this value, the build will expire and the build status will be\n`EXPIRED`.\n\nThe TTL starts ticking from create_time.", "format" "google-duration", "type" "string"}, "id" {"description" "Output only. Unique identifier of the build.", "type" "string"}, "results" {"$ref" "Results", "description" "Output only. Results of the build."}, "createTime" {"description" "Output only. Time at which the request to create the build was received.", "format" "google-datetime", "type" "string"}, "statusDetail" {"description" "Output only. Customer-readable message about the current status.", "type" "string"}, "startTime" {"description" "Output only. Time at which execution of the build was started.", "format" "google-datetime", "type" "string"}, "status" {"type" "string", "enumDescriptions" ["Status of the build is unknown." "Build or step is queued; work has not yet begun." "Build or step is being executed." "Build or step finished successfully." "Build or step failed to complete successfully." "Build or step failed due to an internal cause." "Build or step took longer than was allowed." "Build or step was canceled by a user." "Build was enqueued for longer than the value of `queue_ttl`."], "enum" ["STATUS_UNKNOWN" "QUEUED" "WORKING" "SUCCESS" "FAILURE" "INTERNAL_ERROR" "TIMEOUT" "CANCELLED" "EXPIRED"], "description" "Output only. Status of the build."}, "timeout" {"type" "string", "description" "Amount of time that this build should be allowed to run, to second\ngranularity. If this amount of time elapses, work on the build will cease\nand the build status will be `TIMEOUT`.\n\nDefault time is ten minutes.", "format" "google-duration"}, "buildTriggerId" {"type" "string", "description" "Output only. The ID of the `BuildTrigger` that triggered this build, if it\nwas triggered automatically."}, "substitutions" {"description" "Substitutions data for `Build` resource.", "type" "object", "additionalProperties" {"type" "string"}}, "images" {"description" "A list of images to be pushed upon the successful completion of all build\nsteps.\n\nThe images are pushed using the builder service account's credentials.\n\nThe digests of the pushed images will be stored in the `Build` resource's\nresults field.\n\nIf any of the images fail to be pushed, the build status is marked\n`FAILURE`.", "type" "array", "items" {"type" "string"}}, "source" {"$ref" "Source", "description" "The location of the source files to build."}, "logsBucket" {"description" "Google Cloud Storage bucket where logs should be written (see\n[Bucket Name\nRequirements](https://cloud.google.com/storage/docs/bucket-naming#requirements)).\nLogs file names will be of the format `${logs_bucket}/log-${build_id}.txt`.", "type" "string"}, "projectId" {"description" "Output only. ID of the project.", "type" "string"}, "logUrl" {"description" "Output only. URL to logs for this build in Google Cloud Console.", "type" "string"}, "options" {"$ref" "BuildOptions", "description" "Special options for this build."}, "secrets" {"description" "Secrets to decrypt using Cloud Key Management Service.", "type" "array", "items" {"$ref" "Secret"}}, "timing" {"description" "Output only. Stores timing information for phases of the build. Valid keys\nare:\n\n* BUILD: time to execute all build steps\n* PUSH: time to push all specified images.\n* FETCHSOURCE: time to fetch source.\n\nIf the build does not specify source or images,\nthese keys will not be included.", "type" "object", "additionalProperties" {"$ref" "TimeSpan"}}}}, "ListBuildsResponse" {"description" "Response including listed builds.", "type" "object", "properties" {"builds" {"description" "Builds will be sorted by `create_time`, descending.", "type" "array", "items" {"$ref" "Build"}}, "nextPageToken" {"type" "string", "description" "Token to receive the next page of results."}}, "id" "ListBuildsResponse"}, "ArtifactObjects" {"description" "Files in the workspace to upload to Cloud Storage upon successful\ncompletion of all build steps.", "type" "object", "properties" {"location" {"type" "string", "description" "Cloud Storage bucket and optional object path, in the form\n\"gs://bucket/path/to/somewhere/\". (see [Bucket Name\nRequirements](https://cloud.google.com/storage/docs/bucket-naming#requirements)).\n\nFiles in the workspace matching any path pattern will be uploaded to\nCloud Storage with this location as a prefix."}, "paths" {"description" "Path globs used to match files in the build's workspace.", "type" "array", "items" {"type" "string"}}, "timing" {"description" "Output only. Stores timing information for pushing all artifact objects.", "$ref" "TimeSpan"}}, "id" "ArtifactObjects"}, "StorageSource" {"type" "object", "properties" {"generation" {"type" "string", "description" "Google Cloud Storage generation for the object. If the generation is\nomitted, the latest generation will be used.", "format" "int64"}, "bucket" {"description" "Google Cloud Storage bucket containing the source (see\n[Bucket Name\nRequirements](https://cloud.google.com/storage/docs/bucket-naming#requirements)).", "type" "string"}, "object" {"type" "string", "description" "Google Cloud Storage object containing the source.\n\nThis object must be a gzipped archive file (`.tar.gz`) containing source to\nbuild."}}, "id" "StorageSource", "description" "Location of the source in an archive file in Google Cloud Storage."}, "BuildOptions" {"description" "Optional arguments to enable specific features of builds.", "type" "object", "properties" {"logging" {"enum" ["LOGGING_UNSPECIFIED" "LEGACY" "GCS_ONLY"], "description" "Option to specify the logging mode, which determines where the logs are\nstored.", "type" "string", "enumDescriptions" ["The service determines the logging mode. The default is `LEGACY`. Do not\nrely on the default logging behavior as it may change in the future." "Stackdriver logging and Cloud Storage logging are enabled." "Only Cloud Storage logging is enabled."]}, "logStreamingOption" {"enumDescriptions" ["Service may automatically determine build log streaming behavior." "Build logs should be streamed to Google Cloud Storage." "Build logs should not be streamed to Google Cloud Storage; they will be\nwritten when the build is completed."], "enum" ["STREAM_DEFAULT" "STREAM_ON" "STREAM_OFF"], "description" "Option to define build log streaming behavior to Google Cloud\nStorage.", "type" "string"}, "workerPool" {"type" "string", "description" "Option to specify a `WorkerPool` for the build.\nFormat: projects/{project}/workerPools/{workerPool}\n\nThis field is experimental."}, "volumes" {"description" "Global list of volumes to mount for ALL build steps\n\nEach volume is created as an empty volume prior to starting the build\nprocess. Upon completion of the build, volumes and their contents are\ndiscarded. Global volume names and paths cannot conflict with the volumes\ndefined a build step.\n\nUsing a global volume in a build with only one step is not valid as\nit is indicative of a build request with an incorrect configuration.", "type" "array", "items" {"$ref" "Volume"}}, "requestedVerifyOption" {"enum" ["NOT_VERIFIED" "VERIFIED"], "description" "Requested verifiability options.", "type" "string", "enumDescriptions" ["Not a verifiable build. (default)" "Verified build."]}, "env" {"description" "A list of global environment variable definitions that will exist for all\nbuild steps in this build. If a variable is defined in both globally and in\na build step, the variable will use the build step value.\n\nThe elements are of the form \"KEY=VALUE\" for the environment variable \"KEY\"\nbeing given the value \"VALUE\".", "type" "array", "items" {"type" "string"}}, "machineType" {"enumDescriptions" ["Standard machine type." "Highcpu machine with 8 CPUs." "Highcpu machine with 32 CPUs."], "enum" ["UNSPECIFIED" "N1_HIGHCPU_8" "N1_HIGHCPU_32"], "description" "Compute Engine machine type on which to run the build.", "type" "string"}, "sourceProvenanceHash" {"description" "Requested hash for SourceProvenance.", "type" "array", "items" {"type" "string", "enum" ["NONE" "SHA256" "MD5"]}, "enumDescriptions" ["No hash requested." "Use a sha256 hash." "Use a md5 hash."]}, "substitutionOption" {"enumDescriptions" ["Fails the build if error in substitutions checks, like missing\na substitution in the template or in the map." "Do not fail the build if error in substitutions checks."], "enum" ["MUST_MATCH" "ALLOW_LOOSE"], "description" "Option to specify behavior when there is an error in the substitution\nchecks.", "type" "string"}, "secretEnv" {"type" "array", "items" {"type" "string"}, "description" "A list of global environment variables, which are encrypted using a Cloud\nKey Management Service crypto key. These values must be specified in the\nbuild's `Secret`. These variables will be available to all build steps\nin this build."}, "diskSizeGb" {"description" "Requested disk size for the VM that runs the build. Note that this is *NOT*\n\"disk free\"; some of the space will be used by the operating system and\nbuild utilities. Also note that this is the minimum disk size that will be\nallocated for the build -- the build may run with a larger disk than\nrequested. At present, the maximum disk size is 1000GB; builds that request\nmore than the maximum are rejected with an error.", "format" "int64", "type" "string"}}, "id" "BuildOptions"}, "CancelOperationRequest" {"description" "The request message for Operations.CancelOperation.", "type" "object", "properties" {}, "id" "CancelOperationRequest"}, "CancelBuildRequest" {"description" "Request to cancel an ongoing build.", "type" "object", "properties" {}, "id" "CancelBuildRequest"}, "PullRequestFilter" {"description" "PullRequestFilter contains filter properties for matching GitHub Pull\nRequests.", "type" "object", "properties" {"commentControl" {"enumDescriptions" ["Do not require comments on Pull Requests before builds are triggered." "Enforce that repository owners or collaborators must comment on Pull\nRequests before builds are triggered."], "enum" ["COMMENTS_DISABLED" "COMMENTS_ENABLED"], "description" "Whether to block builds on a \"/gcbrun\" comment from a repository admin or\ncollaborator.", "type" "string"}, "branch" {"type" "string", "description" "Regex of branches to match.\n\nThe syntax of the regular expressions accepted is the syntax accepted by\nRE2 and described at https://github.com/google/re2/wiki/Syntax"}, "invertRegex" {"type" "boolean", "description" "If true, branches that do NOT match the git_ref will trigger a build."}}, "id" "PullRequestFilter"}, "BuildOperationMetadata" {"description" "Metadata for build operations.", "type" "object", "properties" {"build" {"$ref" "Build", "description" "The build that the operation is tracking."}}, "id" "BuildOperationMetadata"}, "Results" {"type" "object", "properties" {"artifactTiming" {"$ref" "TimeSpan", "description" "Time to push all non-container artifacts."}, "buildStepOutputs" {"description" "List of build step outputs, produced by builder images, in the order\ncorresponding to build step indices.\n\n[Cloud Builders](https://cloud.google.com/cloud-build/docs/cloud-builders)\ncan produce this output by writing to `$BUILDER_OUTPUT/output`.\nOnly the first 4KB of data is stored.", "type" "array", "items" {"type" "string", "format" "byte"}}, "images" {"description" "Container images that were built as a part of the build.", "type" "array", "items" {"$ref" "BuiltImage"}}, "numArtifacts" {"description" "Number of artifacts uploaded. Only populated when artifacts are uploaded.", "format" "int64", "type" "string"}, "artifactManifest" {"description" "Path to the artifact manifest. Only populated when artifacts are uploaded.", "type" "string"}, "buildStepImages" {"description" "List of build step digests, in the order corresponding to build step\nindices.", "type" "array", "items" {"type" "string"}}}, "id" "Results", "description" "Artifacts created by the build pipeline."}, "BuiltImage" {"description" "An image built by the pipeline.", "type" "object", "properties" {"name" {"description" "Name used to push the container image to Google Container Registry, as\npresented to `docker push`.", "type" "string"}, "digest" {"type" "string", "description" "Docker Registry 2.0 digest."}, "pushTiming" {"$ref" "TimeSpan", "description" "Output only. Stores timing information for pushing the specified image."}}, "id" "BuiltImage"}, "BuildTrigger" {"description" "Configuration for an automated build in response to source repository\nchanges.", "type" "object", "properties" {"github" {"description" "GitHubEventsConfig describes the configuration of a trigger that creates\na build whenever a GitHub event is received.\n\nMutually exclusive with `trigger_template`.", "$ref" "GitHubEventsConfig"}, "triggerTemplate" {"$ref" "RepoSource", "description" "Template describing the types of source changes to trigger a build.\n\nBranch and tag names in trigger templates are interpreted as regular\nexpressions. Any branch or tag change that matches that regular expression\nwill trigger a build.\n\nMutually exclusive with `github`."}, "tags" {"description" "Tags for annotation of a `BuildTrigger`", "type" "array", "items" {"type" "string"}}, "id" {"description" "Output only. Unique identifier of the trigger.", "type" "string"}, "name" {"type" "string", "description" "User-assigned name of the trigger. Must be unique within the project.\nTrigger names must meet the following requirements:\n\n+ They must contain only alphanumeric characters and dashes.\n+ They can be 1-64 characters long.\n+ They must begin and end with an alphanumeric character."}, "createTime" {"description" "Output only. Time when the trigger was created.", "format" "google-datetime", "type" "string"}, "build" {"description" "Contents of the build template.", "$ref" "Build"}, "ignoredFiles" {"description" "ignored_files and included_files are file glob matches using\nhttps://golang.org/pkg/path/filepath/#Match extended with support for \"**\".\n\nIf ignored_files and changed files are both empty, then they are\nnot used to determine whether or not to trigger a build.\n\nIf ignored_files is not empty, then we ignore any files that match\nany of the ignored_file globs. If the change has no files that are\noutside of the ignored_files globs, then we do not trigger a build.", "type" "array", "items" {"type" "string"}}, "substitutions" {"description" "Substitutions for Build resource. The keys must match the following\nregular expression: `^_[A-Z0-9_]+$`.The keys cannot conflict with the\nkeys in bindings.", "type" "object", "additionalProperties" {"type" "string"}}, "disabled" {"description" "If true, the trigger will never result in a build.", "type" "boolean"}, "includedFiles" {"description" "If any of the files altered in the commit pass the ignored_files\nfilter and included_files is empty, then as far as this filter is\nconcerned, we should trigger the build.\n\nIf any of the files altered in the commit pass the ignored_files\nfilter and included_files is not empty, then we make sure that at\nleast one of those files matches a included_files glob. If not,\nthen we do not trigger a build.", "type" "array", "items" {"type" "string"}}, "filename" {"description" "Path, from the source root, to a file whose contents is used for the\ntemplate.", "type" "string"}, "description" {"type" "string", "description" "Human-readable description of this trigger."}}, "id" "BuildTrigger"}}}